{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/buildLittleWorlds/ml-math-with-densworld/blob/main/modules/01-statistics-probability/notebooks/01-uncertainty-intuition.ipynb)\n\n# Lesson 1: The Intuition of Uncertainty\n\n*\"All maps are wrong, but some are useful.\"* - Vagabu Olt, wandering cartographer\n\n---\n\n## The Core Problem\n\nIn the Capital Archives, scholars study thousands of expedition reports from Yeller Quarry. But they face a fundamental challenge:\n\n- **Population**: All expeditions that have ever been or will be conducted (infinite, unknowable)\n- **Sample**: The 1,000 expedition records we have on file\n\nWhen the Senate asks \"What is the true success rate of Quarry expeditions?\", they're asking about the **population**. But we can only calculate from our **sample**.\n\nThis gap between sample and population is the source of all uncertainty in data science.\n\n---\n\n## Learning Objectives\n\nBy the end of this lesson, you will:\n1. Understand the difference between populations and samples\n2. See why every statistic is an *estimate* with uncertainty\n3. Grasp the concept of a random variable"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Nice plotting defaults\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.rcParams['figure.figsize'] = (10, 6)\n\n# Colab-ready data loading\nBASE_URL = \"https://raw.githubusercontent.com/buildLittleWorlds/ml-math-with-densworld/main/data/\"\n\n# Load the expedition outcomes dataset\nexpeditions = pd.read_csv(BASE_URL + \"expedition_outcomes.csv\")\nprint(f\"Loaded {len(expeditions)} expedition records\")\nexpeditions.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Populations vs. Samples\n",
    "\n",
    "### The Fundamental Truth of the Archives\n",
    "\n",
    "The Boss ran expeditions into Yeller Quarry for 8 years before the disaster. Gull's Remnants continue today. Countless other crews have ventured into the marsh.\n",
    "\n",
    "Our archive contains 1,000 expedition records. But this is just a **sample** of all expeditions that have ever occurred. Many were never recorded. Some records were lost. Others are still being written.\n",
    "\n",
    "Let's pretend, for teaching purposes, that we have access to the \"true\" population of all 100,000 expeditions ever conducted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the \"true population\" of all expeditions\n",
    "# In reality, we'd never have this - it's omniscient knowledge\n",
    "POPULATION_SIZE = 100_000\n",
    "\n",
    "# True parameters (unknown to actual researchers)\n",
    "TRUE_SUCCESS_RATE = 0.72  # 72% of all expeditions are successful\n",
    "TRUE_AVG_CATCH_VALUE = 115  # Average catch value across all time\n",
    "TRUE_CASUALTY_RATE = 0.18  # 18% of expeditions have casualties\n",
    "\n",
    "# Generate the population\n",
    "np.random.seed(42)\n",
    "population = {\n",
    "    'success': np.random.binomial(1, TRUE_SUCCESS_RATE, POPULATION_SIZE),\n",
    "    'catch_value': np.random.lognormal(mean=4.0, sigma=1.0, size=POPULATION_SIZE),\n",
    "    'had_casualties': np.random.binomial(1, TRUE_CASUALTY_RATE, POPULATION_SIZE)\n",
    "}\n",
    "population_df = pd.DataFrame(population)\n",
    "\n",
    "print(f\"Population size: {len(population_df):,}\")\n",
    "print(f\"\\nTrue population statistics (normally unknowable):\")\n",
    "print(f\"  Success rate: {population_df['success'].mean():.1%}\")\n",
    "print(f\"  Average catch value: {population_df['catch_value'].mean():.1f}\")\n",
    "print(f\"  Casualty rate: {population_df['had_casualties'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see what happens when we only have a **sample** - which is the reality scholars in the Archives face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a sample of 100 expeditions (like what an archivist might have)\n",
    "sample_size = 100\n",
    "sample = population_df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "print(f\"Sample size: {len(sample)}\")\n",
    "print(f\"\\nSample statistics (what the archivist calculates):\")\n",
    "print(f\"  Sample success rate: {sample['success'].mean():.1%}\")\n",
    "print(f\"  Sample avg catch value: {sample['catch_value'].mean():.1f}\")\n",
    "print(f\"  Sample casualty rate: {sample['had_casualties'].mean():.1%}\")\n",
    "\n",
    "print(f\"\\nError in estimates:\")\n",
    "print(f\"  Success rate error: {abs(sample['success'].mean() - TRUE_SUCCESS_RATE):.1%}\")\n",
    "print(f\"  Catch value error: {abs(sample['catch_value'].mean() - TRUE_AVG_CATCH_VALUE):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Key Insight\n",
    "\n",
    "Notice that our sample statistics are **close** to the true values, but not exact.\n",
    "\n",
    "This is the fundamental challenge faced by scholars in the Capital Archives: **every measurement is an estimate with error.**\n",
    "\n",
    "When Yasho Krent debates Grigsu Haldo about expedition success rates, they're both working from incomplete samples of an unknowable truth.\n",
    "\n",
    "Let's see how much estimates vary across different samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine 1000 different archivists, each with their own sample of 100 expeditions\n",
    "n_archivists = 1000\n",
    "sample_success_rates = []\n",
    "\n",
    "for _ in range(n_archivists):\n",
    "    archivist_sample = population_df.sample(n=sample_size)\n",
    "    sample_success_rates.append(archivist_sample['success'].mean())\n",
    "\n",
    "sample_success_rates = np.array(sample_success_rates)\n",
    "\n",
    "# Visualize how estimates vary\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(sample_success_rates, bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "ax.axvline(TRUE_SUCCESS_RATE, color='red', linewidth=2, linestyle='--', \n",
    "           label=f'True Rate = {TRUE_SUCCESS_RATE:.0%}')\n",
    "ax.axvline(sample_success_rates.mean(), color='green', linewidth=2, \n",
    "           label=f'Average of Samples = {sample_success_rates.mean():.1%}')\n",
    "ax.set_xlabel('Estimated Success Rate')\n",
    "ax.set_ylabel('Number of Archivists')\n",
    "ax.set_title('1000 Archivists, Each with 100 Expedition Records')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Range of estimates: {sample_success_rates.min():.1%} to {sample_success_rates.max():.1%}\")\n",
    "print(f\"Standard deviation: {sample_success_rates.std():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: The Standard Error - Quantifying Uncertainty\n",
    "\n",
    "The spread of sample estimates is called the **Standard Error**. It tells us how much our estimate might be wrong.\n",
    "\n",
    "There's a beautiful formula:\n",
    "\n",
    "$$\\text{Standard Error} = \\frac{\\sigma}{\\sqrt{n}}$$\n",
    "\n",
    "Where:\n",
    "- $\\sigma$ = population standard deviation\n",
    "- $n$ = sample size\n",
    "\n",
    "### The Semantic Meaning:\n",
    "\n",
    "**Larger samples = Less uncertainty**\n",
    "\n",
    "This is why the Capital demands detailed expedition reports. More data means better estimates. When Gull tells stories of expeditions to young trappers, those stories—if recorded—would reduce our uncertainty about the true nature of Yeller Quarry.\n",
    "\n",
    "Let's verify this with catch values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different sample sizes using catch values\n",
    "sample_sizes = [10, 50, 100, 500, 1000]\n",
    "n_experiments = 500\n",
    "\n",
    "fig, axes = plt.subplots(1, len(sample_sizes), figsize=(16, 4))\n",
    "\n",
    "for idx, n in enumerate(sample_sizes):\n",
    "    means = [population_df.sample(n=n)['catch_value'].mean() for _ in range(n_experiments)]\n",
    "    \n",
    "    axes[idx].hist(means, bins=20, edgecolor='black', alpha=0.7, color='goldenrod')\n",
    "    axes[idx].axvline(population_df['catch_value'].mean(), color='red', linewidth=2)\n",
    "    axes[idx].set_title(f'n = {n}\\nSE = {np.std(means):.1f}')\n",
    "    axes[idx].set_xlabel('Avg Catch Value')\n",
    "    axes[idx].set_xlim(30, 200)\n",
    "    \n",
    "plt.suptitle('How Sample Size Affects Precision of Catch Value Estimates', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"As sample size increases by 4x, standard error decreases by ~2x\")\n",
    "print(\"This is the sqrt(n) relationship in action.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Random Variables - A New Way of Thinking\n",
    "\n",
    "In arithmetic, when we write $x = 5$, we mean $x$ has one specific value.\n",
    "\n",
    "In statistics, a **random variable** is different. It's a variable that can take multiple values, each with a certain probability.\n",
    "\n",
    "### Example: Creature Encounters\n",
    "\n",
    "Let $X$ = the number of creature encounters on an expedition.\n",
    "\n",
    "$X$ doesn't equal any single number. Instead, it follows a distribution:\n",
    "- $P(X = 0) = $ some probability\n",
    "- $P(X = 1) = $ some probability\n",
    "- ... and so on\n",
    "\n",
    "### Why This Matters for the Quarry:\n",
    "\n",
    "When The Boss plans an expedition, she can't know exactly how many creatures they'll encounter. But she can estimate the *distribution* of possibilities based on past expeditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze creature encounters from our actual expedition data\n",
    "encounters = expeditions['creature_encounters']\n",
    "\n",
    "# Count frequencies\n",
    "values, counts = np.unique(encounters, return_counts=True)\n",
    "frequencies = counts / len(encounters)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(values, frequencies, edgecolor='black', alpha=0.7, color='darkred')\n",
    "ax.set_xlabel('Number of Creature Encounters')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_title('Distribution of Creature Encounters per Expedition\\n(Random Variable X = encounters)')\n",
    "ax.set_xticks(values)\n",
    "plt.show()\n",
    "\n",
    "print(\"Probability distribution of creature encounters:\")\n",
    "for v, p in zip(values[:10], frequencies[:10]):\n",
    "    print(f\"  P(X = {v}) = {p:.3f}\")\n",
    "if len(values) > 10:\n",
    "    print(f\"  ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Expedition Planning\n",
    "\n",
    "The Boss doesn't know she'll have exactly 3 encounters. But she knows:\n",
    "- The *expected value* (mean) of encounters\n",
    "- The *variance* (spread) of possibilities\n",
    "\n",
    "This probabilistic thinking is what separates experienced crew leaders from novices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary statistics for creature encounters:\")\n",
    "print(f\"  Expected (mean): {encounters.mean():.1f} encounters\")\n",
    "print(f\"  Standard deviation: {encounters.std():.1f}\")\n",
    "print(f\"  Minimum observed: {encounters.min()}\")\n",
    "print(f\"  Maximum observed: {encounters.max()}\")\n",
    "print(f\"\\nThe Boss prepares for {encounters.mean():.0f} encounters,\")\n",
    "print(f\"but knows it could reasonably be as high as {int(encounters.mean() + 2*encounters.std())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Working with Real Expedition Data\n",
    "\n",
    "Let's apply these concepts to our actual expedition archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our sample from the archives\n",
    "print(\"=\" * 50)\n",
    "print(\"YELLER QUARRY EXPEDITION ARCHIVE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total records: {len(expeditions)}\")\n",
    "print(f\"Years covered: {expeditions['year'].min()} - {expeditions['year'].max()}\")\n",
    "\n",
    "print(f\"\\n--- Estimated Statistics (with uncertainty) ---\")\n",
    "\n",
    "# Success rate with standard error\n",
    "success_rate = expeditions['success'].mean()\n",
    "success_se = np.sqrt(success_rate * (1 - success_rate) / len(expeditions))\n",
    "print(f\"\\nSuccess Rate: {success_rate:.1%} ± {1.96*success_se:.1%} (95% CI)\")\n",
    "\n",
    "# Average catch value with standard error\n",
    "catch_mean = expeditions['catch_value'].mean()\n",
    "catch_se = expeditions['catch_value'].std() / np.sqrt(len(expeditions))\n",
    "print(f\"Avg Catch Value: {catch_mean:.1f} ± {1.96*catch_se:.1f} (95% CI)\")\n",
    "\n",
    "# Casualty rate\n",
    "casualty_rate = (expeditions['casualties'] > 0).mean()\n",
    "casualty_se = np.sqrt(casualty_rate * (1 - casualty_rate) / len(expeditions))\n",
    "print(f\"Casualty Rate: {casualty_rate:.1%} ± {1.96*casualty_se:.1%} (95% CI)\")\n",
    "\n",
    "print(f\"\\n(The ± values represent our uncertainty due to limited sample size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **You never see the truth** - only samples from an unknown population. The Archives contain shadows, not the reality of Yeller Quarry.\n",
    "\n",
    "2. **Every statistic is an estimate** - the sample success rate is not the true success rate, it's our best guess with attached uncertainty.\n",
    "\n",
    "3. **Larger samples = less uncertainty** - the Standard Error shrinks as $\\frac{1}{\\sqrt{n}}$. This is why detailed records matter.\n",
    "\n",
    "4. **Random variables map outcomes to probabilities** - creature encounters aren't deterministic, they follow a distribution. Experienced crews think probabilistically.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. **Sector Analysis**: Compare success rates between the 'Deep Quarry' sector and 'Surface Flats'. Which has higher success? Calculate the standard error for each.\n",
    "\n",
    "2. **Sample Size Experiment**: Take random samples of size 25, 100, and 400 from the expedition data. How much does the catch value estimate vary?\n",
    "\n",
    "3. **Yeller Groups**: Expeditions with Yeller groups are rare (~10%). Calculate the success rate for expeditions with and without Yeller groups. Given the small sample size of Yeller expeditions, how confident can we be in the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Sector Analysis\n",
    "# Hint: Use expeditions[expeditions['sector'] == 'Deep Quarry'] to filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Sample Size Experiment\n",
    "# Hint: Use expeditions.sample(n=25)['catch_value'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Yeller Group Analysis\n",
    "# Hint: expeditions['has_yeller_group'] is True/False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Lesson\n",
    "\n",
    "In **Lesson 2: Distributions as Terrain**, we'll explore the creature market price data and learn to recognize when your data violates the assumptions that standard models make. The long-tailed distribution of prices tells a story about the Quarry's economy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}