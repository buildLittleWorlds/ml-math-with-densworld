{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/buildLittleWorlds/ml-math-with-densworld/blob/main/modules/01-statistics-probability/notebooks/02-distributions-as-terrain.ipynb)\n",
    "\n",
    "# Lesson 2: Distributions as Terrain\n",
    "\n",
    "*\"The price of a Grimslew is as unpredictable as the creature itself—most trades are quick copper exchanges for common specimens, but once in a generation, a perfect Mottled Lungfish sells for enough to buy a Senate seat.\"*  \n",
    "— Ledger annotation, Capital Creature Market, 1847\n",
    "\n",
    "---\n",
    "\n",
    "## The Core Problem\n",
    "\n",
    "In the Capital's creature market, merchants face a peculiar challenge: **most sales are small, but rare sales are enormous**. A seller who prices inventory based on the average sale will go bankrupt—because the average is pulled upward by rare, spectacular transactions that may never repeat.\n",
    "\n",
    "Meanwhile, in the Dens, mapmakers recording ground stability face the opposite problem: their measurement errors cluster predictably around the true value, with large errors being genuinely rare.\n",
    "\n",
    "These are two different **terrains of possibility**. Understanding the shape of your data's terrain is essential before applying any statistical model.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lesson, you will:\n",
    "1. Recognize the normal distribution and understand why it emerges from accumulated small effects\n",
    "2. Identify skewed distributions and understand why mean ≠ median\n",
    "3. Know when standard statistical models will fail due to distribution shape\n",
    "4. Transform skewed data to enable standard analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Nice plotting defaults\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Colab-ready data loading\n",
    "BASE_URL = \"https://raw.githubusercontent.com/buildLittleWorlds/ml-math-with-densworld/main/data/\"\n",
    "\n",
    "# Load the datasets\n",
    "creature_market = pd.read_csv(BASE_URL + \"creature_market.csv\")\n",
    "dens_boundary = pd.read_csv(BASE_URL + \"dens_boundary_observations.csv\")\n",
    "\n",
    "print(f\"Loaded {len(creature_market)} creature market transactions\")\n",
    "print(f\"Loaded {len(dens_boundary)} boundary observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The Normal Distribution — Measurement Errors in the Dens\n",
    "\n",
    "### The Mapmakers' Dilemma\n",
    "\n",
    "In the Dens, where \"yesterday's map is gossip,\" mapmakers like Vagabu Olt and The Pickbox Man spend their lives surveying the shifting boundaries between solid ground and densmuck. Their instruments—theodolites, measuring rods, even simple pacing—all introduce small errors.\n",
    "\n",
    "But here's the remarkable thing: when you accumulate many independent small effects, the errors follow a predictable pattern called the **normal distribution** (or Gaussian, or bell curve).\n",
    "\n",
    "Let's examine the measurement errors from our boundary observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract measurement errors (difference between observed and true stability)\n",
    "errors = dens_boundary['measurement_error']\n",
    "\n",
    "# Plot the distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(errors, bins=40, density=True, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "\n",
    "# Overlay theoretical normal distribution\n",
    "x = np.linspace(errors.min(), errors.max(), 100)\n",
    "axes[0].plot(x, stats.norm.pdf(x, errors.mean(), errors.std()), \n",
    "             'r-', linewidth=2, label='Normal distribution')\n",
    "axes[0].axvline(0, color='green', linestyle='--', linewidth=2, label='Zero error')\n",
    "axes[0].set_xlabel('Measurement Error')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title('Distribution of Mapmaker Measurement Errors')\n",
    "axes[0].legend()\n",
    "\n",
    "# Q-Q plot to test normality\n",
    "stats.probplot(errors, dist=\"norm\", plot=axes[1])\n",
    "axes[1].set_title('Q-Q Plot: Do Errors Follow Normal Distribution?')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean error: {errors.mean():.4f} (should be near 0 if unbiased)\")\n",
    "print(f\"Standard deviation: {errors.std():.4f}\")\n",
    "print(f\"Median error: {errors.median():.4f}\")\n",
    "print(f\"\\nNote: Mean ≈ Median for symmetric distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why the Bell Curve Emerges\n",
    "\n",
    "A mapmaker's measurement error comes from many independent sources:\n",
    "- Slight trembling of the hand\n",
    "- Wind affecting the theodolite\n",
    "- Imperfect calibration\n",
    "- Judgment calls on where exactly the boundary lies\n",
    "- Fatigue\n",
    "\n",
    "Each source contributes a tiny positive or negative error. When you **add up many independent random effects**, the result follows a normal distribution—regardless of what each individual effect looks like.\n",
    "\n",
    "This is a preview of the **Central Limit Theorem**, which we'll explore deeply in Lesson 3.\n",
    "\n",
    "### The 68-95-99.7 Rule\n",
    "\n",
    "For normal distributions, we can make precise probability statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = errors.mean()\n",
    "std = errors.std()\n",
    "\n",
    "within_1_std = ((errors >= mean - std) & (errors <= mean + std)).mean()\n",
    "within_2_std = ((errors >= mean - 2*std) & (errors <= mean + 2*std)).mean()\n",
    "within_3_std = ((errors >= mean - 3*std) & (errors <= mean + 3*std)).mean()\n",
    "\n",
    "print(\"The 68-95-99.7 Rule for Normal Distributions:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Within 1 std: {within_1_std:.1%} (theory: 68.3%)\")\n",
    "print(f\"Within 2 std: {within_2_std:.1%} (theory: 95.4%)\")\n",
    "print(f\"Within 3 std: {within_3_std:.1%} (theory: 99.7%)\")\n",
    "\n",
    "print(f\"\\nPractical interpretation for mapmakers:\")\n",
    "print(f\"  - Most errors ({within_1_std:.0%}) are within ±{std:.3f}\")\n",
    "print(f\"  - Errors beyond ±{2*std:.3f} are rare ({1-within_2_std:.1%})\")\n",
    "print(f\"  - Errors beyond ±{3*std:.3f} almost never happen ({1-within_3_std:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrument Quality Matters\n",
    "\n",
    "Different instruments have different precision. Let's compare the measurement error distributions by instrument type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "instruments = dens_boundary['instrument_type'].unique()\n",
    "colors = ['steelblue', 'coral', 'seagreen']\n",
    "\n",
    "for instrument, color in zip(instruments, colors):\n",
    "    subset = dens_boundary[dens_boundary['instrument_type'] == instrument]['measurement_error']\n",
    "    ax.hist(subset, bins=30, alpha=0.5, label=f'{instrument} (std={subset.std():.4f})', \n",
    "            color=color, density=True)\n",
    "\n",
    "ax.axvline(0, color='black', linestyle='--', linewidth=2)\n",
    "ax.set_xlabel('Measurement Error')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Measurement Error by Instrument Type')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPrecision by instrument (lower std = more precise):\")\n",
    "for instrument in instruments:\n",
    "    subset = dens_boundary[dens_boundary['instrument_type'] == instrument]['measurement_error']\n",
    "    print(f\"  {instrument:15s}: std = {subset.std():.4f}, mean = {subset.mean():+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Skewed Distributions — The Creature Market\n",
    "\n",
    "### A Very Different Terrain\n",
    "\n",
    "Now let's look at creature market prices. Unlike measurement errors, prices don't cluster symmetrically around a center. Instead, they exhibit **right skew**: most transactions are small, but rare transactions are enormous.\n",
    "\n",
    "*\"For every hundred specimens of Swamp Hornet sold for pocket change, there's one collector who'll pay a year's wages for a pristine Grimslew.\"*  \n",
    "— Market proverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = creature_market['price_per_unit']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of raw prices\n",
    "axes[0].hist(prices, bins=50, color='goldenrod', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(prices.mean(), color='red', linewidth=2, linestyle='-', \n",
    "                label=f'Mean = {prices.mean():.1f}')\n",
    "axes[0].axvline(prices.median(), color='blue', linewidth=2, linestyle='--', \n",
    "                label=f'Median = {prices.median():.1f}')\n",
    "axes[0].set_xlabel('Price per Unit')\n",
    "axes[0].set_ylabel('Number of Transactions')\n",
    "axes[0].set_title('Creature Market Prices: Right-Skewed Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# Log-scale histogram\n",
    "axes[1].hist(np.log10(prices + 1), bins=50, color='goldenrod', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Log₁₀(Price + 1)')\n",
    "axes[1].set_ylabel('Number of Transactions')\n",
    "axes[1].set_title('Log-Transformed Prices: More Symmetric')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Price statistics:\")\n",
    "print(f\"  Mean:   {prices.mean():>10.2f}\")\n",
    "print(f\"  Median: {prices.median():>10.2f}\")\n",
    "print(f\"  Min:    {prices.min():>10.2f}\")\n",
    "print(f\"  Max:    {prices.max():>10.2f}\")\n",
    "print(f\"\\n  Mean / Median ratio: {prices.mean() / prices.median():.2f}\")\n",
    "print(f\"  (For symmetric distributions, this ratio ≈ 1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Mean ≠ Median Matters\n",
    "\n",
    "In a symmetric distribution (like mapmaker errors), the mean and median are nearly equal. But in a skewed distribution, they diverge.\n",
    "\n",
    "**The mean is pulled toward the tail.** A few extremely expensive specimens drag the average upward, even though most transactions are much smaller.\n",
    "\n",
    "This has practical implications:\n",
    "- If you're a **seller**, the mean might make your inventory seem more valuable than it is\n",
    "- If you're a **buyer**, the median better represents what you'll actually pay\n",
    "- If you're a **statistician**, many formulas assume symmetry and will give misleading results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate how extreme values affect the mean\n",
    "print(\"The Influence of Extreme Values\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Original statistics\n",
    "print(f\"\\nAll {len(prices)} transactions:\")\n",
    "print(f\"  Mean:   {prices.mean():.2f}\")\n",
    "print(f\"  Median: {prices.median():.2f}\")\n",
    "\n",
    "# Remove top 1%\n",
    "threshold_99 = prices.quantile(0.99)\n",
    "prices_trimmed = prices[prices <= threshold_99]\n",
    "print(f\"\\nWithout top 1% (prices > {threshold_99:.2f}):\")\n",
    "print(f\"  Mean:   {prices_trimmed.mean():.2f}  (dropped {(prices.mean() - prices_trimmed.mean()):.2f})\")\n",
    "print(f\"  Median: {prices_trimmed.median():.2f}  (barely changed)\")\n",
    "\n",
    "# Remove top 5%\n",
    "threshold_95 = prices.quantile(0.95)\n",
    "prices_more_trimmed = prices[prices <= threshold_95]\n",
    "print(f\"\\nWithout top 5% (prices > {threshold_95:.2f}):\")\n",
    "print(f\"  Mean:   {prices_more_trimmed.mean():.2f}\")\n",
    "print(f\"  Median: {prices_more_trimmed.median():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Log-Normal Distribution\n",
    "\n",
    "Creature prices follow what's called a **log-normal distribution**. This means:\n",
    "- The prices themselves are skewed\n",
    "- But the **logarithm** of prices is normally distributed\n",
    "\n",
    "Why does this happen? Prices are affected by **multiplicative factors**:\n",
    "- Rarity multiplies the base price\n",
    "- Condition (pristine vs. damaged) multiplies again\n",
    "- Collector demand multiplies again\n",
    "\n",
    "When factors multiply rather than add, you get log-normal distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test log-normality\n",
    "log_prices = np.log(prices + 1)  # Add 1 to handle any zeros\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Q-Q plot for raw prices (should NOT be linear)\n",
    "stats.probplot(prices, dist=\"norm\", plot=axes[0])\n",
    "axes[0].set_title('Q-Q Plot: Raw Prices vs. Normal\\n(Not linear = not normal)')\n",
    "\n",
    "# Q-Q plot for log prices (should BE linear)\n",
    "stats.probplot(log_prices, dist=\"norm\", plot=axes[1])\n",
    "axes[1].set_title('Q-Q Plot: Log Prices vs. Normal\\n(Linear = log-normal)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: When Models Fail — Distribution Assumptions\n",
    "\n",
    "Many statistical models assume your data follows a normal distribution (or at least a symmetric one). When this assumption is violated, results can be misleading.\n",
    "\n",
    "### Example: Confidence Intervals for Mean Price\n",
    "\n",
    "The standard formula for a 95% confidence interval assumes normality:\n",
    "\n",
    "$$\\text{CI} = \\bar{x} \\pm 1.96 \\times \\frac{s}{\\sqrt{n}}$$\n",
    "\n",
    "Let's see what happens when we apply this to skewed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard CI calculation\n",
    "n = len(prices)\n",
    "mean = prices.mean()\n",
    "std = prices.std()\n",
    "se = std / np.sqrt(n)\n",
    "\n",
    "ci_lower = mean - 1.96 * se\n",
    "ci_upper = mean + 1.96 * se\n",
    "\n",
    "print(\"Standard 95% Confidence Interval for Mean Price\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Point estimate: {mean:.2f}\")\n",
    "print(f\"95% CI: [{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
    "\n",
    "print(\"\\n⚠️  Problems with this approach:\")\n",
    "print(f\"  - The CI is symmetric around the mean\")\n",
    "print(f\"  - But the data is NOT symmetric\")\n",
    "print(f\"  - The lower bound ({ci_lower:.2f}) is closer to the median ({prices.median():.2f})\")\n",
    "print(f\"  - The upper bound may underestimate rare high prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap: A Distribution-Free Alternative\n",
    "\n",
    "When your data is skewed, **bootstrapping** provides a more honest confidence interval. It works by:\n",
    "1. Resampling your data with replacement\n",
    "2. Calculating the statistic for each resample\n",
    "3. Using the percentiles of these resampled statistics as the CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap confidence interval\n",
    "n_bootstrap = 10000\n",
    "bootstrap_means = []\n",
    "\n",
    "for _ in range(n_bootstrap):\n",
    "    resample = np.random.choice(prices, size=n, replace=True)\n",
    "    bootstrap_means.append(resample.mean())\n",
    "\n",
    "bootstrap_means = np.array(bootstrap_means)\n",
    "boot_ci_lower = np.percentile(bootstrap_means, 2.5)\n",
    "boot_ci_upper = np.percentile(bootstrap_means, 97.5)\n",
    "\n",
    "print(\"Bootstrap 95% Confidence Interval for Mean Price\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Point estimate: {mean:.2f}\")\n",
    "print(f\"95% CI: [{boot_ci_lower:.2f}, {boot_ci_upper:.2f}]\")\n",
    "\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Standard CI: [{ci_lower:.2f}, {ci_upper:.2f}]  (symmetric)\")\n",
    "print(f\"  Bootstrap CI: [{boot_ci_lower:.2f}, {boot_ci_upper:.2f}]  (asymmetric)\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(bootstrap_means, bins=50, color='goldenrod', edgecolor='black', alpha=0.7)\n",
    "ax.axvline(mean, color='red', linewidth=2, label=f'Sample Mean = {mean:.1f}')\n",
    "ax.axvline(boot_ci_lower, color='blue', linewidth=2, linestyle='--', label=f'2.5th percentile')\n",
    "ax.axvline(boot_ci_upper, color='blue', linewidth=2, linestyle='--', label=f'97.5th percentile')\n",
    "ax.set_xlabel('Bootstrap Sample Mean')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Bootstrap Distribution of Mean Price')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Kurtosis and Fat Tails\n",
    "\n",
    "Beyond skewness, another important distribution property is **kurtosis**—how heavy the tails are compared to a normal distribution.\n",
    "\n",
    "In the Quarry, expedition casualties exhibit **fat tails**: most expeditions have zero or few casualties, but catastrophic events (creature attacks, cave-ins) occasionally kill many crew members at once.\n",
    "\n",
    "Let's examine this with our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load expedition data to examine casualties\n",
    "expeditions = pd.read_csv(BASE_URL + \"expedition_outcomes.csv\")\n",
    "\n",
    "casualties = expeditions['casualties']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of casualties\n",
    "axes[0].hist(casualties, bins=30, color='darkred', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Casualties per Expedition')\n",
    "axes[0].set_ylabel('Number of Expeditions')\n",
    "axes[0].set_title('Distribution of Expedition Casualties')\n",
    "\n",
    "# Compare to normal distribution with same mean/std\n",
    "x = np.linspace(0, casualties.max(), 100)\n",
    "normal_pdf = stats.norm.pdf(x, casualties.mean(), casualties.std())\n",
    "axes[1].hist(casualties, bins=30, density=True, color='darkred', edgecolor='black', alpha=0.5, label='Actual')\n",
    "axes[1].plot(x, normal_pdf, 'b-', linewidth=2, label='Normal (same mean/std)')\n",
    "axes[1].set_xlabel('Casualties per Expedition')\n",
    "axes[1].set_ylabel('Density')\n",
    "axes[1].set_title('Casualties vs. Normal Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Casualty statistics:\")\n",
    "print(f\"  Mean: {casualties.mean():.2f}\")\n",
    "print(f\"  Std:  {casualties.std():.2f}\")\n",
    "print(f\"  Skewness: {stats.skew(casualties):.2f}  (>0 means right-skewed)\")\n",
    "print(f\"  Excess Kurtosis: {stats.kurtosis(casualties):.2f}  (>0 means fatter tails than normal)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Fat Tails Matter\n",
    "\n",
    "If you model casualty risk using a normal distribution, you will **systematically underestimate catastrophic events**. The normal distribution says 3-sigma events are vanishingly rare. But in fat-tailed distributions, they happen more often than you'd expect.\n",
    "\n",
    "*\"The Quarry doesn't kill in ones and twos. It waits until your guard is down, then takes the whole crew.\"*  \n",
    "— Gull's Remnants saying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare tail probabilities: actual vs. normal assumption\n",
    "mean_c = casualties.mean()\n",
    "std_c = casualties.std()\n",
    "\n",
    "thresholds = [mean_c + 2*std_c, mean_c + 3*std_c, mean_c + 4*std_c]\n",
    "\n",
    "print(\"Probability of Extreme Casualties\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Threshold':<20} {'Actual':<15} {'Normal Predicts':<15} {'Ratio':<10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for t in thresholds:\n",
    "    actual = (casualties > t).mean()\n",
    "    normal_pred = 1 - stats.norm.cdf(t, mean_c, std_c)\n",
    "    ratio = actual / normal_pred if normal_pred > 0 else float('inf')\n",
    "    print(f\">{t:>5.1f} casualties  {actual:>10.4f}      {normal_pred:>10.6f}      {ratio:>8.1f}x\")\n",
    "\n",
    "print(f\"\\n⚠️  Extreme events happen MORE often than normal distribution predicts!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Identifying Distribution Types\n",
    "\n",
    "Here's a practical guide for recognizing distribution shapes in your data:\n",
    "\n",
    "| Characteristic | Normal | Log-Normal | Fat-Tailed |\n",
    "|---------------|--------|------------|------------|\n",
    "| Symmetry | Symmetric | Right-skewed | Often right-skewed |\n",
    "| Mean vs Median | Equal | Mean > Median | Mean > Median |\n",
    "| Q-Q Plot | Linear | Curved up-right | S-shaped |\n",
    "| Extreme values | Very rare | Somewhat common | More common than expected |\n",
    "| Example | Measurement errors | Prices, incomes | Casualties, extreme events |\n",
    "\n",
    "### Decision Tree for Distribution Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose_distribution(data, name=\"Data\"):\n",
    "    \"\"\"Diagnose the distribution type of a dataset.\"\"\"\n",
    "    \n",
    "    mean_val = data.mean()\n",
    "    median_val = data.median()\n",
    "    skew_val = stats.skew(data)\n",
    "    kurt_val = stats.kurtosis(data)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Distribution Diagnosis: {name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Mean:     {mean_val:.3f}\")\n",
    "    print(f\"Median:   {median_val:.3f}\")\n",
    "    print(f\"Mean/Median Ratio: {mean_val/median_val:.2f}\")\n",
    "    print(f\"Skewness: {skew_val:.2f}\")\n",
    "    print(f\"Excess Kurtosis: {kurt_val:.2f}\")\n",
    "    \n",
    "    print(f\"\\nDiagnosis:\")\n",
    "    \n",
    "    # Check symmetry\n",
    "    if abs(skew_val) < 0.5:\n",
    "        print(f\"  ✓ Approximately symmetric (skew = {skew_val:.2f})\")\n",
    "    elif skew_val > 0:\n",
    "        print(f\"  → Right-skewed (skew = {skew_val:.2f})\")\n",
    "    else:\n",
    "        print(f\"  ← Left-skewed (skew = {skew_val:.2f})\")\n",
    "    \n",
    "    # Check tails\n",
    "    if abs(kurt_val) < 1:\n",
    "        print(f\"  ✓ Normal-like tails (kurtosis = {kurt_val:.2f})\")\n",
    "    elif kurt_val > 0:\n",
    "        print(f\"  ⚠️  Fat tails - extreme values more likely (kurtosis = {kurt_val:.2f})\")\n",
    "    else:\n",
    "        print(f\"  ⚠️  Thin tails - extreme values less likely (kurtosis = {kurt_val:.2f})\")\n",
    "    \n",
    "    # Recommendation\n",
    "    print(f\"\\nRecommendation:\")\n",
    "    if abs(skew_val) < 0.5 and abs(kurt_val) < 1:\n",
    "        print(f\"  → Standard normal-based methods should work well\")\n",
    "    elif skew_val > 1:\n",
    "        print(f\"  → Consider log transformation or log-normal models\")\n",
    "        print(f\"  → Use median instead of mean for central tendency\")\n",
    "    if kurt_val > 2:\n",
    "        print(f\"  → Use robust methods (bootstrap, trimmed means)\")\n",
    "        print(f\"  → Be cautious of 'rare event' underestimation\")\n",
    "\n",
    "# Diagnose our datasets\n",
    "diagnose_distribution(dens_boundary['measurement_error'], \"Mapmaker Measurement Errors\")\n",
    "diagnose_distribution(creature_market['price_per_unit'], \"Creature Market Prices\")\n",
    "diagnose_distribution(expeditions['casualties'], \"Expedition Casualties\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Concept | Key Insight | Densworld Example |\n",
    "|---------|-------------|-------------------|\n",
    "| Normal Distribution | Emerges from many small, additive effects | Mapmaker measurement errors |\n",
    "| Skewness | Mean ≠ Median; mean pulled toward tail | Creature market prices |\n",
    "| Log-Normal | Multiplicative factors create log-normal data | Price = base × rarity × condition × demand |\n",
    "| Fat Tails | Extreme events more likely than normal predicts | Expedition casualties |\n",
    "| 68-95-99.7 Rule | Only works for normal distributions | Mapmaker errors stay in bounds |\n",
    "| Bootstrap | Distribution-free confidence intervals | Works for any terrain |\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Creature Categories\n",
    "\n",
    "Different creature categories may have different price distributions. Compare the price distribution for `insect` vs `mammal` categories. Which is more skewed? Why might this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "# Hint: creature_market[creature_market['category'] == 'insect']['price_per_unit']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experience and Precision\n",
    "\n",
    "Do more experienced mapmakers have smaller measurement errors? Calculate the standard deviation of `measurement_error` grouped by `observer_experience` (you may want to bin experience into categories like 0-10, 11-20, 21+ years)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "# Hint: pd.cut() can bin continuous variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Transform and Test\n",
    "\n",
    "Apply a log transformation to creature prices. Then:\n",
    "1. Calculate the mean and median of the log-transformed prices\n",
    "2. Create a Q-Q plot to verify the transformed data is approximately normal\n",
    "3. Calculate a 95% confidence interval for the mean of log-prices\n",
    "4. Transform this CI back to the original scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n",
    "# Hint: Use np.log() to transform, np.exp() to back-transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Tail Risk Assessment\n",
    "\n",
    "The Boss is planning a large expedition and wants to understand casualty risk. What is the probability of suffering 5 or more casualties on an expedition? Calculate this:\n",
    "1. From the actual data (empirical probability)\n",
    "2. Assuming a normal distribution\n",
    "3. Assuming a Poisson distribution (often used for count data)\n",
    "\n",
    "Which assumption is most conservative (predicts highest risk)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Your code here\n",
    "# Hint: stats.poisson.sf(k, mu) gives P(X > k) for Poisson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Lesson\n",
    "\n",
    "In **Lesson 3: The Central Limit Theorem**, we'll discover why averaging many observations reveals truth—even when individual observations are noisy and non-normal. We'll follow mapmakers as they combine multiple surveys to find the true boundary of the Dens.\n",
    "\n",
    "*\"One measurement is a guess. Ten measurements are a vote. A hundred measurements are the truth.\"*  \n",
    "— Vagabu Olt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
