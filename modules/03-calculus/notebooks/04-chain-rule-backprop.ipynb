{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/buildLittleWorlds/ml-math-with-densworld/blob/main/modules/03-calculus/notebooks/04-chain-rule-backprop.ipynb)\n",
    "\n",
    "# Lesson 4: The Chain Rule and Backpropagation\n",
    "\n",
    "*\"The Tower of Mirado does not respond directly to my actions. My stratagems affect my troops' morale, which affects their effectiveness, which affects the damage we inflict, which affects the Tower's defenses, which affects my progress. Layer upon layer of cause and effect. To understand how my initial choice propagates through this chain—this is the deepest question of optimization.\"*  \n",
    "— The Colonel, Year 20 of the Siege\n",
    "\n",
    "---\n",
    "\n",
    "## The Core Insight\n",
    "\n",
    "Neural networks are **nested functions**—layers upon layers of transformations. To train them, we need the gradient of the loss with respect to every weight in every layer.\n",
    "\n",
    "The **chain rule** tells us how to compute these gradients by **propagating sensitivity backward** through the network.\n",
    "\n",
    "If $y = f(g(x))$, then:\n",
    "\n",
    "$$\\frac{dy}{dx} = \\frac{dy}{dg} \\cdot \\frac{dg}{dx}$$\n",
    "\n",
    "In words: *The sensitivity of y to x is the product of sensitivities along the chain.*\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lesson, you will:\n",
    "1. Apply the chain rule to composite functions\n",
    "2. Understand computational graphs and forward/backward passes\n",
    "3. Implement backpropagation from scratch for a simple network\n",
    "4. Connect backpropagation to the Colonel's layered decision-making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Nice plotting defaults\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Colab-ready data loading\n",
    "BASE_URL = \"https://raw.githubusercontent.com/buildLittleWorlds/ml-math-with-densworld/main/data/\"\n",
    "\n",
    "# Load data\n",
    "stratagem = pd.read_csv(BASE_URL + \"stratagem_details.csv\")\n",
    "expedition = pd.read_csv(BASE_URL + \"expedition_outcomes.csv\")\n",
    "\n",
    "print(f\"Loaded {len(stratagem)} stratagem records\")\n",
    "print(f\"Loaded {len(expedition)} expedition records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Part 1: The Chain Rule — Sensitivity Through Layers\n",
    "\n",
    "### The Simple Case: Two Functions\n",
    "\n",
    "Consider:\n",
    "- $g(x) = x^2$ (inner function)\n",
    "- $f(g) = \\sin(g)$ (outer function)\n",
    "- $y = f(g(x)) = \\sin(x^2)$ (composite)\n",
    "\n",
    "How does $y$ change when we nudge $x$?\n",
    "\n",
    "$$\\frac{dy}{dx} = \\frac{df}{dg} \\cdot \\frac{dg}{dx} = \\cos(x^2) \\cdot 2x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate chain rule\n",
    "def g(x):\n",
    "    return x**2\n",
    "\n",
    "def f(u):\n",
    "    return np.sin(u)\n",
    "\n",
    "def composite(x):\n",
    "    return f(g(x))\n",
    "\n",
    "def dg_dx(x):\n",
    "    return 2 * x\n",
    "\n",
    "def df_dg(u):\n",
    "    return np.cos(u)\n",
    "\n",
    "def dy_dx_chain(x):\n",
    "    \"\"\"Chain rule: dy/dx = df/dg * dg/dx\"\"\"\n",
    "    return df_dg(g(x)) * dg_dx(x)\n",
    "\n",
    "# Numerical verification\n",
    "def numerical_derivative(func, x, h=1e-5):\n",
    "    return (func(x + h) - func(x - h)) / (2 * h)\n",
    "\n",
    "# Test at several points\n",
    "test_points = [0.5, 1.0, 1.5, 2.0]\n",
    "\n",
    "print(\"Chain Rule Verification:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'x':>8} | {'Chain Rule':>15} | {'Numerical':>15} | Match?\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for x in test_points:\n",
    "    chain = dy_dx_chain(x)\n",
    "    numerical = numerical_derivative(composite, x)\n",
    "    match = \"Yes\" if np.isclose(chain, numerical) else \"No\"\n",
    "    print(f\"{x:>8.2f} | {chain:>15.6f} | {numerical:>15.6f} | {match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the chain rule\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "x = np.linspace(0.1, 2.5, 100)\n",
    "\n",
    "# Top left: The composite function\n",
    "axes[0, 0].plot(x, composite(x), 'b-', linewidth=2)\n",
    "axes[0, 0].set_xlabel('x', fontsize=11)\n",
    "axes[0, 0].set_ylabel('y = sin(x²)', fontsize=11)\n",
    "axes[0, 0].set_title('Composite Function: f(g(x)) = sin(x²)', fontsize=12)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Top right: Inner function g(x) = x²\n",
    "axes[0, 1].plot(x, g(x), 'g-', linewidth=2, label='g(x) = x²')\n",
    "axes[0, 1].plot(x, dg_dx(x), 'g--', linewidth=2, label=\"g'(x) = 2x\")\n",
    "axes[0, 1].set_xlabel('x', fontsize=11)\n",
    "axes[0, 1].set_ylabel('g(x) and g\\'(x)', fontsize=11)\n",
    "axes[0, 1].set_title('Inner Function and Its Derivative', fontsize=12)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom left: Outer function f(u) = sin(u)\n",
    "u = np.linspace(0, 6, 100)\n",
    "axes[1, 0].plot(u, f(u), 'r-', linewidth=2, label='f(u) = sin(u)')\n",
    "axes[1, 0].plot(u, df_dg(u), 'r--', linewidth=2, label=\"f'(u) = cos(u)\")\n",
    "axes[1, 0].set_xlabel('u = g(x)', fontsize=11)\n",
    "axes[1, 0].set_ylabel('f(u) and f\\'(u)', fontsize=11)\n",
    "axes[1, 0].set_title('Outer Function and Its Derivative', fontsize=12)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom right: The chain rule derivative\n",
    "axes[1, 1].plot(x, dy_dx_chain(x), 'purple', linewidth=2, label=\"dy/dx = cos(x²) · 2x\")\n",
    "axes[1, 1].axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].set_xlabel('x', fontsize=11)\n",
    "axes[1, 1].set_ylabel('dy/dx', fontsize=11)\n",
    "axes[1, 1].set_title('Chain Rule Result: dy/dx = df/dg · dg/dx', fontsize=12)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Part 2: The Colonel's Chain of Causation\n",
    "\n",
    "*\"When I commit more personnel, it does not directly reduce the Tower's defenses. Instead, it flows through channels: more personnel → higher morale → more effective assaults → more damage → reduced defenses → progress. Each link in the chain multiplies or diminishes the effect.\"*  \n",
    "— The Colonel\n",
    "\n",
    "Let's model this chain:\n",
    "\n",
    "1. **Personnel** → affects **Morale**\n",
    "2. **Morale** → affects **Assault Effectiveness**\n",
    "3. **Assault Effectiveness** → affects **Progress**\n",
    "\n",
    "This is exactly like a neural network with three layers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model the Colonel's chain of causation\n",
    "def personnel_to_morale(personnel, w1=0.001):\n",
    "    \"\"\"More personnel → higher morale (with saturation)\"\"\"\n",
    "    return np.tanh(w1 * personnel)\n",
    "\n",
    "def morale_to_effectiveness(morale, w2=1.5):\n",
    "    \"\"\"Higher morale → more effective assaults\"\"\"\n",
    "    return w2 * morale\n",
    "\n",
    "def effectiveness_to_progress(effectiveness, w3=0.05):\n",
    "    \"\"\"Higher effectiveness → more progress (with noise)\"\"\"\n",
    "    return w3 * effectiveness\n",
    "\n",
    "def full_chain(personnel, w1=0.001, w2=1.5, w3=0.05):\n",
    "    \"\"\"Full forward pass through the chain.\"\"\"\n",
    "    morale = personnel_to_morale(personnel, w1)\n",
    "    effectiveness = morale_to_effectiveness(morale, w2)\n",
    "    progress = effectiveness_to_progress(effectiveness, w3)\n",
    "    return progress\n",
    "\n",
    "# Compute chain rule derivative: d(progress)/d(personnel)\n",
    "def chain_rule_derivative(personnel, w1=0.001, w2=1.5, w3=0.05):\n",
    "    \"\"\"Apply chain rule: d(progress)/d(personnel) = d(progress)/d(eff) * d(eff)/d(morale) * d(morale)/d(personnel)\"\"\"\n",
    "    morale = personnel_to_morale(personnel, w1)\n",
    "    \n",
    "    # d(morale)/d(personnel) = w1 * sech²(w1 * personnel) = w1 * (1 - tanh²(w1 * personnel))\n",
    "    d_morale_d_personnel = w1 * (1 - morale**2)\n",
    "    \n",
    "    # d(effectiveness)/d(morale) = w2\n",
    "    d_eff_d_morale = w2\n",
    "    \n",
    "    # d(progress)/d(effectiveness) = w3\n",
    "    d_progress_d_eff = w3\n",
    "    \n",
    "    # Chain rule: multiply all the derivatives\n",
    "    d_progress_d_personnel = d_progress_d_eff * d_eff_d_morale * d_morale_d_personnel\n",
    "    \n",
    "    return d_progress_d_personnel\n",
    "\n",
    "# Visualize\n",
    "personnel_range = np.linspace(0, 100, 100)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Chain components\n",
    "morale = [personnel_to_morale(p) for p in personnel_range]\n",
    "effectiveness = [morale_to_effectiveness(m) for m in morale]\n",
    "progress = [effectiveness_to_progress(e) for e in effectiveness]\n",
    "\n",
    "axes[0].plot(personnel_range, morale, 'b-', linewidth=2)\n",
    "axes[0].set_xlabel('Personnel', fontsize=11)\n",
    "axes[0].set_ylabel('Morale', fontsize=11)\n",
    "axes[0].set_title('Layer 1: Personnel → Morale', fontsize=12)\n",
    "\n",
    "axes[1].plot(morale, effectiveness, 'g-', linewidth=2)\n",
    "axes[1].set_xlabel('Morale', fontsize=11)\n",
    "axes[1].set_ylabel('Effectiveness', fontsize=11)\n",
    "axes[1].set_title('Layer 2: Morale → Effectiveness', fontsize=12)\n",
    "\n",
    "axes[2].plot(effectiveness, progress, 'r-', linewidth=2)\n",
    "axes[2].set_xlabel('Effectiveness', fontsize=11)\n",
    "axes[2].set_ylabel('Progress', fontsize=11)\n",
    "axes[2].set_title('Layer 3: Effectiveness → Progress', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show end-to-end and the chain rule derivative\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: End-to-end function\n",
    "progress_values = [full_chain(p) for p in personnel_range]\n",
    "axes[0].plot(personnel_range, progress_values, 'purple', linewidth=2)\n",
    "axes[0].set_xlabel('Personnel', fontsize=11)\n",
    "axes[0].set_ylabel('Progress', fontsize=11)\n",
    "axes[0].set_title('End-to-End: Personnel → Progress', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Chain rule derivative\n",
    "chain_derivs = [chain_rule_derivative(p) for p in personnel_range]\n",
    "numerical_derivs = [numerical_derivative(full_chain, p) for p in personnel_range]\n",
    "\n",
    "axes[1].plot(personnel_range, chain_derivs, 'r-', linewidth=2, label='Chain Rule')\n",
    "axes[1].plot(personnel_range, numerical_derivs, 'b--', linewidth=2, label='Numerical')\n",
    "axes[1].set_xlabel('Personnel', fontsize=11)\n",
    "axes[1].set_ylabel('d(Progress)/d(Personnel)', fontsize=11)\n",
    "axes[1].set_title('Gradient Through the Chain\\n(Chain Rule = Numerical)', fontsize=12)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The chain rule derivative matches the numerical derivative exactly!\")\n",
    "print(\"This is how backpropagation computes gradients efficiently.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Part 3: Computational Graphs\n",
    "\n",
    "Neural networks can be represented as **computational graphs**:\n",
    "- **Nodes** are operations (add, multiply, activation functions)\n",
    "- **Edges** carry values forward and gradients backward\n",
    "\n",
    "### The Two Passes:\n",
    "\n",
    "1. **Forward Pass**: Compute output from inputs\n",
    "2. **Backward Pass**: Compute gradients from output to inputs\n",
    "\n",
    "Let's implement a simple computational graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeNode:\n",
    "    \"\"\"\n",
    "    A node in a computational graph.\n",
    "    Tracks value, gradient, and operation.\n",
    "    \"\"\"\n",
    "    def __init__(self, value, name=\"\"):\n",
    "        self.value = value\n",
    "        self.grad = 0.0  # Gradient will be accumulated here\n",
    "        self.name = name\n",
    "        self.children = []  # Operations that produced this node\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.name}(value={self.value:.4f}, grad={self.grad:.4f})\"\n",
    "\n",
    "def multiply(a, b, name=\"\"):\n",
    "    \"\"\"Multiply two nodes.\"\"\"\n",
    "    result = ComputeNode(a.value * b.value, name=name)\n",
    "    \n",
    "    def backward():\n",
    "        # d(a*b)/da = b, d(a*b)/db = a\n",
    "        a.grad += result.grad * b.value\n",
    "        b.grad += result.grad * a.value\n",
    "    \n",
    "    result.children = [(a, b, backward)]\n",
    "    return result\n",
    "\n",
    "def add(a, b, name=\"\"):\n",
    "    \"\"\"Add two nodes.\"\"\"\n",
    "    result = ComputeNode(a.value + b.value, name=name)\n",
    "    \n",
    "    def backward():\n",
    "        # d(a+b)/da = 1, d(a+b)/db = 1\n",
    "        a.grad += result.grad * 1\n",
    "        b.grad += result.grad * 1\n",
    "    \n",
    "    result.children = [(a, b, backward)]\n",
    "    return result\n",
    "\n",
    "def sigmoid(a, name=\"\"):\n",
    "    \"\"\"Sigmoid activation.\"\"\"\n",
    "    sig_val = 1 / (1 + np.exp(-a.value))\n",
    "    result = ComputeNode(sig_val, name=name)\n",
    "    \n",
    "    def backward():\n",
    "        # d(sigmoid)/da = sigmoid * (1 - sigmoid)\n",
    "        a.grad += result.grad * sig_val * (1 - sig_val)\n",
    "    \n",
    "    result.children = [(a, None, backward)]\n",
    "    return result\n",
    "\n",
    "def backward_pass(output):\n",
    "    \"\"\"\n",
    "    Perform backward pass from output node.\n",
    "    Uses topological sort to ensure correct order.\n",
    "    \"\"\"\n",
    "    # Build topological order\n",
    "    topo = []\n",
    "    visited = set()\n",
    "    \n",
    "    def build_topo(node):\n",
    "        if id(node) not in visited:\n",
    "            visited.add(id(node))\n",
    "            for child_tuple in node.children:\n",
    "                for child in child_tuple[:-1]:  # Exclude the backward function\n",
    "                    if child is not None:\n",
    "                        build_topo(child)\n",
    "            topo.append(node)\n",
    "    \n",
    "    build_topo(output)\n",
    "    \n",
    "    # Backward pass\n",
    "    output.grad = 1.0  # Start with gradient of 1 at output\n",
    "    for node in reversed(topo):\n",
    "        for child_tuple in node.children:\n",
    "            backward_fn = child_tuple[-1]\n",
    "            backward_fn()\n",
    "\n",
    "# Example: Simple computation\n",
    "print(\"Example: y = (x * w1 + b1) * w2\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Forward pass\n",
    "x = ComputeNode(2.0, name=\"x\")\n",
    "w1 = ComputeNode(3.0, name=\"w1\")\n",
    "b1 = ComputeNode(1.0, name=\"b1\")\n",
    "w2 = ComputeNode(0.5, name=\"w2\")\n",
    "\n",
    "# Compute graph\n",
    "xw1 = multiply(x, w1, name=\"x*w1\")\n",
    "xw1_b1 = add(xw1, b1, name=\"x*w1+b1\")\n",
    "y = multiply(xw1_b1, w2, name=\"y\")\n",
    "\n",
    "print(f\"Forward pass:\")\n",
    "print(f\"  x = {x.value}, w1 = {w1.value}, b1 = {b1.value}, w2 = {w2.value}\")\n",
    "print(f\"  x * w1 = {xw1.value}\")\n",
    "print(f\"  x * w1 + b1 = {xw1_b1.value}\")\n",
    "print(f\"  y = (x * w1 + b1) * w2 = {y.value}\")\n",
    "\n",
    "# Backward pass\n",
    "backward_pass(y)\n",
    "\n",
    "print(f\"\\nBackward pass (gradients):\")\n",
    "print(f\"  dy/dx = {x.grad}\")\n",
    "print(f\"  dy/dw1 = {w1.grad}\")\n",
    "print(f\"  dy/db1 = {b1.grad}\")\n",
    "print(f\"  dy/dw2 = {w2.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify with numerical derivatives\n",
    "def compute_y(x_val, w1_val, b1_val, w2_val):\n",
    "    return (x_val * w1_val + b1_val) * w2_val\n",
    "\n",
    "h = 1e-5\n",
    "\n",
    "print(\"Verification with Numerical Derivatives:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# dy/dx\n",
    "dy_dx_numerical = (compute_y(2.0 + h, 3.0, 1.0, 0.5) - compute_y(2.0 - h, 3.0, 1.0, 0.5)) / (2*h)\n",
    "print(f\"dy/dx: Backprop = {x.grad:.4f}, Numerical = {dy_dx_numerical:.4f}\")\n",
    "\n",
    "# dy/dw1\n",
    "dy_dw1_numerical = (compute_y(2.0, 3.0 + h, 1.0, 0.5) - compute_y(2.0, 3.0 - h, 1.0, 0.5)) / (2*h)\n",
    "print(f\"dy/dw1: Backprop = {w1.grad:.4f}, Numerical = {dy_dw1_numerical:.4f}\")\n",
    "\n",
    "# dy/db1\n",
    "dy_db1_numerical = (compute_y(2.0, 3.0, 1.0 + h, 0.5) - compute_y(2.0, 3.0, 1.0 - h, 0.5)) / (2*h)\n",
    "print(f\"dy/db1: Backprop = {b1.grad:.4f}, Numerical = {dy_db1_numerical:.4f}\")\n",
    "\n",
    "# dy/dw2\n",
    "dy_dw2_numerical = (compute_y(2.0, 3.0, 1.0, 0.5 + h) - compute_y(2.0, 3.0, 1.0, 0.5 - h)) / (2*h)\n",
    "print(f\"dy/dw2: Backprop = {w2.grad:.4f}, Numerical = {dy_dw2_numerical:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Part 4: A Simple Neural Network from Scratch\n",
    "\n",
    "Now let's implement a complete neural network with backpropagation:\n",
    "\n",
    "- **Input layer**: Takes features\n",
    "- **Hidden layer**: Linear transformation + activation\n",
    "- **Output layer**: Final prediction\n",
    "- **Loss**: Mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNetwork:\n",
    "    \"\"\"\n",
    "    A simple 2-layer neural network with backpropagation.\n",
    "    Architecture: Input -> Hidden (with ReLU) -> Output\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights with small random values\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * 0.1\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * 0.1\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "        \n",
    "        # Cache for backward pass\n",
    "        self.cache = {}\n",
    "    \n",
    "    def relu(self, x):\n",
    "        \"\"\"ReLU activation.\"\"\"\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def relu_derivative(self, x):\n",
    "        \"\"\"Derivative of ReLU.\"\"\"\n",
    "        return (x > 0).astype(float)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Returns predictions and caches intermediate values.\n",
    "        \"\"\"\n",
    "        # Layer 1\n",
    "        self.cache['X'] = X\n",
    "        self.cache['Z1'] = X @ self.W1 + self.b1\n",
    "        self.cache['A1'] = self.relu(self.cache['Z1'])\n",
    "        \n",
    "        # Layer 2 (output)\n",
    "        self.cache['Z2'] = self.cache['A1'] @ self.W2 + self.b2\n",
    "        \n",
    "        return self.cache['Z2']  # No activation on output for regression\n",
    "    \n",
    "    def backward(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Backward pass using the chain rule.\n",
    "        \n",
    "        Computes gradients for all weights and biases.\n",
    "        \"\"\"\n",
    "        m = y_true.shape[0]  # Number of samples\n",
    "        \n",
    "        # Output layer gradients\n",
    "        # dL/dZ2 = dL/dy_pred * dy_pred/dZ2 = 2*(y_pred - y_true) / m * 1\n",
    "        dZ2 = 2 * (y_pred - y_true) / m\n",
    "        \n",
    "        # dL/dW2 = dL/dZ2 * dZ2/dW2 = A1.T @ dZ2\n",
    "        self.dW2 = self.cache['A1'].T @ dZ2\n",
    "        self.db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
    "        \n",
    "        # Hidden layer gradients (chain rule continues)\n",
    "        # dL/dA1 = dL/dZ2 * dZ2/dA1 = dZ2 @ W2.T\n",
    "        dA1 = dZ2 @ self.W2.T\n",
    "        \n",
    "        # dL/dZ1 = dL/dA1 * dA1/dZ1 = dA1 * relu'(Z1)\n",
    "        dZ1 = dA1 * self.relu_derivative(self.cache['Z1'])\n",
    "        \n",
    "        # dL/dW1 = dL/dZ1 * dZ1/dW1 = X.T @ dZ1\n",
    "        self.dW1 = self.cache['X'].T @ dZ1\n",
    "        self.db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
    "    \n",
    "    def update(self, learning_rate):\n",
    "        \"\"\"Update weights using gradients.\"\"\"\n",
    "        self.W2 -= learning_rate * self.dW2\n",
    "        self.b2 -= learning_rate * self.db2\n",
    "        self.W1 -= learning_rate * self.dW1\n",
    "        self.b1 -= learning_rate * self.db1\n",
    "    \n",
    "    def loss(self, y_true, y_pred):\n",
    "        \"\"\"Mean squared error loss.\"\"\"\n",
    "        return np.mean((y_pred - y_true)**2)\n",
    "\n",
    "print(\"SimpleNeuralNetwork class defined!\")\n",
    "print(\"Architecture: Input -> Hidden (ReLU) -> Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data from stratagem records\n",
    "features = ['personnel_committed', 'supply_cost', 'risk_level', 'colonel_confidence']\n",
    "\n",
    "X = stratagem[features].values\n",
    "y = stratagem['progress_delta'].values.reshape(-1, 1)\n",
    "\n",
    "# Normalize\n",
    "X_mean, X_std = X.mean(axis=0), X.std(axis=0)\n",
    "X_norm = (X - X_mean) / X_std\n",
    "\n",
    "y_mean, y_std = y.mean(), y.std()\n",
    "y_norm = (y - y_mean) / y_std\n",
    "\n",
    "# Train/test split\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X_norm[:split], X_norm[split:]\n",
    "y_train, y_test = y_norm[:split], y_norm[split:]\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the neural network\n",
    "nn = SimpleNeuralNetwork(input_size=4, hidden_size=8, output_size=1)\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_epochs = 500\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    y_pred_train = nn.forward(X_train)\n",
    "    \n",
    "    # Compute loss\n",
    "    train_loss = nn.loss(y_train, y_pred_train)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Backward pass (this is backpropagation!)\n",
    "    nn.backward(y_train, y_pred_train)\n",
    "    \n",
    "    # Update weights\n",
    "    nn.update(learning_rate)\n",
    "    \n",
    "    # Compute test loss\n",
    "    y_pred_test = nn.forward(X_test)\n",
    "    test_loss = nn.loss(y_test, y_pred_test)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch:4d}: Train Loss = {train_loss:.6f}, Test Loss = {test_loss:.6f}\")\n",
    "\n",
    "print(f\"\\nFinal: Train Loss = {train_losses[-1]:.6f}, Test Loss = {test_losses[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Loss curves\n",
    "axes[0].plot(train_losses, 'b-', linewidth=2, label='Train')\n",
    "axes[0].plot(test_losses, 'r-', linewidth=2, label='Test')\n",
    "axes[0].set_xlabel('Epoch', fontsize=11)\n",
    "axes[0].set_ylabel('MSE Loss', fontsize=11)\n",
    "axes[0].set_title('Training Progress (Backpropagation in Action)', fontsize=12)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Predictions vs actual\n",
    "y_pred_final = nn.forward(X_test)\n",
    "axes[1].scatter(y_test, y_pred_final, alpha=0.6, s=40)\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "             'r--', linewidth=2, label='Perfect prediction')\n",
    "axes[1].set_xlabel('Actual (normalized)', fontsize=11)\n",
    "axes[1].set_ylabel('Predicted (normalized)', fontsize=11)\n",
    "axes[1].set_title('Predictions vs Actual on Test Set', fontsize=12)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Part 5: Visualizing Gradients Through Layers\n",
    "\n",
    "Let's trace how gradients flow backward through our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze gradient magnitudes through layers\n",
    "# Run one forward and backward pass to get fresh gradients\n",
    "y_pred = nn.forward(X_train)\n",
    "nn.backward(y_train, y_pred)\n",
    "\n",
    "# Gradient statistics\n",
    "print(\"Gradient Statistics Through Layers:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "layers = [\n",
    "    ('Layer 1 Weights (dW1)', nn.dW1),\n",
    "    ('Layer 1 Biases (db1)', nn.db1),\n",
    "    ('Layer 2 Weights (dW2)', nn.dW2),\n",
    "    ('Layer 2 Biases (db2)', nn.db2)\n",
    "]\n",
    "\n",
    "for name, grad in layers:\n",
    "    print(f\"{name:30}: mean={grad.mean():.6f}, std={grad.std():.6f}, \"\n",
    "          f\"min={grad.min():.6f}, max={grad.max():.6f}\")\n",
    "\n",
    "# Visualize gradient distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(nn.dW1.flatten(), bins=30, alpha=0.7, label='Layer 1 Weights', color='blue')\n",
    "axes[0].hist(nn.dW2.flatten(), bins=30, alpha=0.7, label='Layer 2 Weights', color='red')\n",
    "axes[0].set_xlabel('Gradient Value', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Gradient Distributions', fontsize=12)\n",
    "axes[0].legend()\n",
    "\n",
    "# Gradient magnitude over training\n",
    "# Re-run training to collect gradient norms\n",
    "nn2 = SimpleNeuralNetwork(input_size=4, hidden_size=8, output_size=1)\n",
    "grad_norms_W1 = []\n",
    "grad_norms_W2 = []\n",
    "\n",
    "for epoch in range(200):\n",
    "    y_pred = nn2.forward(X_train)\n",
    "    nn2.backward(y_train, y_pred)\n",
    "    \n",
    "    grad_norms_W1.append(np.linalg.norm(nn2.dW1))\n",
    "    grad_norms_W2.append(np.linalg.norm(nn2.dW2))\n",
    "    \n",
    "    nn2.update(0.01)\n",
    "\n",
    "axes[1].plot(grad_norms_W1, 'b-', linewidth=2, label='Layer 1 (dW1)')\n",
    "axes[1].plot(grad_norms_W2, 'r-', linewidth=2, label='Layer 2 (dW2)')\n",
    "axes[1].set_xlabel('Epoch', fontsize=11)\n",
    "axes[1].set_ylabel('Gradient Norm', fontsize=11)\n",
    "axes[1].set_title('Gradient Magnitude Over Training', fontsize=12)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Part 6: The Vanishing/Exploding Gradient Problem\n",
    "\n",
    "In deep networks, gradients can become very small (vanishing) or very large (exploding) as they flow backward through many layers.\n",
    "\n",
    "*\"The deeper the chain of causation, the fainter the signal becomes. By the time I trace the effect of a decision made years ago through all the intervening events, the connection is nearly invisible. This is the vanishing gradient—the forgetting of distant causes.\"*  \n",
    "— The Colonel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate vanishing gradients with sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "# Chain of sigmoid layers\n",
    "def deep_chain_gradient(x, num_layers):\n",
    "    \"\"\"Compute gradient through a chain of sigmoid layers.\"\"\"\n",
    "    # Forward pass\n",
    "    activations = [x]\n",
    "    current = x\n",
    "    for _ in range(num_layers):\n",
    "        current = sigmoid(current)\n",
    "        activations.append(current)\n",
    "    \n",
    "    # Backward pass (chain rule)\n",
    "    gradient = 1.0\n",
    "    for i in range(num_layers - 1, -1, -1):\n",
    "        gradient *= sigmoid_derivative(activations[i])\n",
    "    \n",
    "    return gradient\n",
    "\n",
    "# Test with different depths\n",
    "depths = [1, 5, 10, 20, 50]\n",
    "x_values = np.linspace(-2, 2, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for depth in depths:\n",
    "    gradients = [deep_chain_gradient(x, depth) for x in x_values]\n",
    "    ax.plot(x_values, gradients, linewidth=2, label=f'Depth = {depth}')\n",
    "\n",
    "ax.set_xlabel('Input x', fontsize=11)\n",
    "ax.set_ylabel('Gradient Magnitude', fontsize=11)\n",
    "ax.set_title('Vanishing Gradients in Deep Sigmoid Networks', fontsize=12)\n",
    "ax.legend()\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"As depth increases, gradients vanish exponentially!\")\n",
    "print(\"This is why ReLU and skip connections were invented.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Manual Backpropagation\n",
    "\n",
    "For the function $f(x) = (x^2 + 3)^3$, use the chain rule to compute $\\frac{df}{dx}$ and verify numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Chain rule by hand\n",
    "\n",
    "def f(x):\n",
    "    return (x**2 + 3)**3\n",
    "\n",
    "def df_dx_chain_rule(x):\n",
    "    \"\"\"\n",
    "    Chain rule:\n",
    "    Let u = x^2 + 3\n",
    "    f = u^3\n",
    "    \n",
    "    df/dx = df/du * du/dx\n",
    "          = 3u^2 * 2x\n",
    "          = 3(x^2 + 3)^2 * 2x\n",
    "          = 6x(x^2 + 3)^2\n",
    "    \"\"\"\n",
    "    return 6 * x * (x**2 + 3)**2\n",
    "\n",
    "# Verify\n",
    "print(\"Exercise 1: Chain Rule Verification\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for x in [1, 2, 3]:\n",
    "    analytical = df_dx_chain_rule(x)\n",
    "    numerical = numerical_derivative(f, x)\n",
    "    print(f\"x = {x}: Chain Rule = {analytical:.4f}, Numerical = {numerical:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "### Exercise 2: Add a Third Layer\n",
    "\n",
    "Extend the SimpleNeuralNetwork class to have two hidden layers instead of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Three-layer network\n",
    "\n",
    "class ThreeLayerNetwork:\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size, output_size):\n",
    "        self.W1 = np.random.randn(input_size, hidden1_size) * 0.1\n",
    "        self.b1 = np.zeros((1, hidden1_size))\n",
    "        self.W2 = np.random.randn(hidden1_size, hidden2_size) * 0.1\n",
    "        self.b2 = np.zeros((1, hidden2_size))\n",
    "        self.W3 = np.random.randn(hidden2_size, output_size) * 0.1\n",
    "        self.b3 = np.zeros((1, output_size))\n",
    "        self.cache = {}\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def relu_derivative(self, x):\n",
    "        return (x > 0).astype(float)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.cache['X'] = X\n",
    "        self.cache['Z1'] = X @ self.W1 + self.b1\n",
    "        self.cache['A1'] = self.relu(self.cache['Z1'])\n",
    "        self.cache['Z2'] = self.cache['A1'] @ self.W2 + self.b2\n",
    "        self.cache['A2'] = self.relu(self.cache['Z2'])\n",
    "        self.cache['Z3'] = self.cache['A2'] @ self.W3 + self.b3\n",
    "        return self.cache['Z3']\n",
    "    \n",
    "    def backward(self, y_true, y_pred):\n",
    "        m = y_true.shape[0]\n",
    "        \n",
    "        # Output layer\n",
    "        dZ3 = 2 * (y_pred - y_true) / m\n",
    "        self.dW3 = self.cache['A2'].T @ dZ3\n",
    "        self.db3 = np.sum(dZ3, axis=0, keepdims=True)\n",
    "        \n",
    "        # Hidden layer 2\n",
    "        dA2 = dZ3 @ self.W3.T\n",
    "        dZ2 = dA2 * self.relu_derivative(self.cache['Z2'])\n",
    "        self.dW2 = self.cache['A1'].T @ dZ2\n",
    "        self.db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
    "        \n",
    "        # Hidden layer 1\n",
    "        dA1 = dZ2 @ self.W2.T\n",
    "        dZ1 = dA1 * self.relu_derivative(self.cache['Z1'])\n",
    "        self.dW1 = self.cache['X'].T @ dZ1\n",
    "        self.db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
    "    \n",
    "    def update(self, lr):\n",
    "        self.W3 -= lr * self.dW3\n",
    "        self.b3 -= lr * self.db3\n",
    "        self.W2 -= lr * self.dW2\n",
    "        self.b2 -= lr * self.db2\n",
    "        self.W1 -= lr * self.dW1\n",
    "        self.b1 -= lr * self.db1\n",
    "    \n",
    "    def loss(self, y_true, y_pred):\n",
    "        return np.mean((y_pred - y_true)**2)\n",
    "\n",
    "# Train\n",
    "nn3 = ThreeLayerNetwork(4, 8, 4, 1)\n",
    "losses_3layer = []\n",
    "\n",
    "for epoch in range(300):\n",
    "    y_pred = nn3.forward(X_train)\n",
    "    loss = nn3.loss(y_train, y_pred)\n",
    "    losses_3layer.append(loss)\n",
    "    nn3.backward(y_train, y_pred)\n",
    "    nn3.update(0.01)\n",
    "\n",
    "print(f\"Three-layer network: Final loss = {losses_3layer[-1]:.6f}\")\n",
    "\n",
    "# Compare to 2-layer\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses[:300], 'b-', label='2-layer network')\n",
    "plt.plot(losses_3layer, 'r-', label='3-layer network')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Comparing 2-layer vs 3-layer Networks')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "### Exercise 3: Gradient Checking\n",
    "\n",
    "Implement a gradient check that verifies backpropagation is correct by comparing to numerical gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Gradient checking\n",
    "\n",
    "def gradient_check(nn, X, y, epsilon=1e-5):\n",
    "    \"\"\"\n",
    "    Check gradients by comparing to numerical approximation.\n",
    "    \"\"\"\n",
    "    # Forward and backward pass\n",
    "    y_pred = nn.forward(X)\n",
    "    nn.backward(y, y_pred)\n",
    "    \n",
    "    # Check W1 gradients\n",
    "    numerical_dW1 = np.zeros_like(nn.W1)\n",
    "    \n",
    "    for i in range(nn.W1.shape[0]):\n",
    "        for j in range(nn.W1.shape[1]):\n",
    "            # Plus epsilon\n",
    "            nn.W1[i, j] += epsilon\n",
    "            y_plus = nn.forward(X)\n",
    "            loss_plus = nn.loss(y, y_plus)\n",
    "            \n",
    "            # Minus epsilon\n",
    "            nn.W1[i, j] -= 2 * epsilon\n",
    "            y_minus = nn.forward(X)\n",
    "            loss_minus = nn.loss(y, y_minus)\n",
    "            \n",
    "            # Restore\n",
    "            nn.W1[i, j] += epsilon\n",
    "            \n",
    "            # Numerical gradient\n",
    "            numerical_dW1[i, j] = (loss_plus - loss_minus) / (2 * epsilon)\n",
    "    \n",
    "    # Compare\n",
    "    difference = np.linalg.norm(numerical_dW1 - nn.dW1) / (np.linalg.norm(numerical_dW1) + np.linalg.norm(nn.dW1))\n",
    "    \n",
    "    return difference, numerical_dW1, nn.dW1\n",
    "\n",
    "# Test\n",
    "nn_check = SimpleNeuralNetwork(4, 4, 1)\n",
    "X_small = X_train[:10]\n",
    "y_small = y_train[:10]\n",
    "\n",
    "diff, num_grad, bp_grad = gradient_check(nn_check, X_small, y_small)\n",
    "\n",
    "print(\"Gradient Check Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Relative difference: {diff:.10f}\")\n",
    "print(f\"(Should be < 1e-5 for correct implementation)\")\n",
    "\n",
    "if diff < 1e-5:\n",
    "    print(\"\\nGradient check PASSED!\")\n",
    "else:\n",
    "    print(\"\\nGradient check FAILED. Check backprop implementation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "### Exercise 4: The Colonel's Decision Tree\n",
    "\n",
    "Model a multi-stage decision process where each stage feeds into the next, and compute how the final outcome's gradient flows back to the initial decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: The Colonel's decision chain\n",
    "\n",
    "class ColonelDecisionChain:\n",
    "    \"\"\"\n",
    "    Model the Colonel's multi-stage decision process:\n",
    "    \n",
    "    Initial Decision → Troop Morale → Assault Success → Progress\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Weights for each stage\n",
    "        self.w_decision_to_morale = 0.5\n",
    "        self.w_morale_to_assault = 0.8\n",
    "        self.w_assault_to_progress = 0.3\n",
    "    \n",
    "    def forward(self, decision):\n",
    "        \"\"\"Forward pass through the decision chain.\"\"\"\n",
    "        self.decision = decision\n",
    "        self.morale = np.tanh(self.w_decision_to_morale * decision)\n",
    "        self.assault = self.w_morale_to_assault * self.morale\n",
    "        self.progress = self.w_assault_to_progress * self.assault\n",
    "        return self.progress\n",
    "    \n",
    "    def backward(self):\n",
    "        \"\"\"Backward pass: compute d(progress)/d(decision).\"\"\"\n",
    "        # d(progress)/d(assault)\n",
    "        d_progress_d_assault = self.w_assault_to_progress\n",
    "        \n",
    "        # d(assault)/d(morale)\n",
    "        d_assault_d_morale = self.w_morale_to_assault\n",
    "        \n",
    "        # d(morale)/d(decision) = w * (1 - tanh^2(w * decision))\n",
    "        d_morale_d_decision = self.w_decision_to_morale * (1 - self.morale**2)\n",
    "        \n",
    "        # Chain rule\n",
    "        self.gradient = d_progress_d_assault * d_assault_d_morale * d_morale_d_decision\n",
    "        return self.gradient\n",
    "\n",
    "# Test\n",
    "chain = ColonelDecisionChain()\n",
    "\n",
    "decisions = np.linspace(-5, 5, 100)\n",
    "progress_values = [chain.forward(d) for d in decisions]\n",
    "gradients = [chain.backward() for d in decisions for _ in [chain.forward(d)]]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(decisions, progress_values, 'b-', linewidth=2)\n",
    "axes[0].set_xlabel('Initial Decision', fontsize=11)\n",
    "axes[0].set_ylabel('Final Progress', fontsize=11)\n",
    "axes[0].set_title('Colonel\\'s Decision Chain: Input → Output', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "gradients_clean = []\n",
    "for d in decisions:\n",
    "    chain.forward(d)\n",
    "    gradients_clean.append(chain.backward())\n",
    "\n",
    "axes[1].plot(decisions, gradients_clean, 'r-', linewidth=2)\n",
    "axes[1].set_xlabel('Initial Decision', fontsize=11)\n",
    "axes[1].set_ylabel('d(Progress)/d(Decision)', fontsize=11)\n",
    "axes[1].set_title('Gradient Through the Chain (Backpropagation)', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The gradient tells the Colonel: 'If you increase your initial decision,\")\n",
    "print(\"here is how much your final progress will change.'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Concept | Key Insight | Colonel's Siege Example |\n",
    "|---------|-------------|------------------------|\n",
    "| **Chain Rule** | Multiply sensitivities along the chain | d(progress)/d(decision) = d(progress)/d(assault) × d(assault)/d(morale) × d(morale)/d(decision) |\n",
    "| **Computational Graph** | Break computation into nodes and edges | Each stage of the siege is a node |\n",
    "| **Forward Pass** | Compute output from inputs | Decision → Morale → Assault → Progress |\n",
    "| **Backward Pass** | Compute gradients from output to inputs | Propagate sensitivity backward through the chain |\n",
    "| **Backpropagation** | Efficient application of chain rule | One forward + one backward pass gives all gradients |\n",
    "| **Vanishing Gradients** | Deep chains attenuate gradients | Effects of long-ago decisions become invisible |\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **The chain rule is the foundation**: It tells us how to propagate sensitivity through nested functions.\n",
    "\n",
    "2. **Backpropagation is efficient**: One forward pass, one backward pass, and we have all gradients.\n",
    "\n",
    "3. **Computational graphs make it systematic**: Any differentiable computation can be broken into nodes with local gradients.\n",
    "\n",
    "4. **Depth can cause problems**: Vanishing/exploding gradients are real challenges in deep networks.\n",
    "\n",
    "5. **This is how neural networks learn**: Every adjustment to every weight in every layer comes from backpropagation.\n",
    "\n",
    "---\n",
    "\n",
    "## Module 3 Complete!\n",
    "\n",
    "You have now completed the Calculus module. You understand:\n",
    "\n",
    "1. **Derivatives as sensitivity** — how outputs respond to input changes\n",
    "2. **Gradients as compasses** — vectors pointing uphill in parameter space\n",
    "3. **Gradient descent** — the core optimization algorithm\n",
    "4. **Backpropagation** — efficient computation of gradients in deep networks\n",
    "\n",
    "In **Module 4: Applied ML**, we'll bring everything together: statistics, linear algebra, and calculus—to derive linear regression, understand regularization, and build a complete machine learning pipeline.\n",
    "\n",
    "*\"Twenty years of siegecraft have taught me the gradient. Twenty years of small adjustments, each informed by the last, each feeding into the next. The Tower has not yet fallen—but I understand now the shape of the landscape I navigate. This is the power of calculus: not to see the future, but to feel which way is down.\"*  \n",
    "— The Colonel, final entry, Year 20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
