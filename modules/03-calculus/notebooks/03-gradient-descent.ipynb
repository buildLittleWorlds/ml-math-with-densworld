{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/buildLittleWorlds/ml-math-with-densworld/blob/main/modules/03-calculus/notebooks/03-gradient-descent.ipynb)\n",
    "\n",
    "# Lesson 3: Gradient Descent — Walking Downhill\n",
    "\n",
    "*\"For twenty years I have walked this invisible landscape. Each step guided not by sight but by feel—the subtle shift of ground beneath my feet telling me: uphill, downhill, plateau. I cannot see the valley where the Tower falls, but I can feel my way toward it, one step at a time. This is optimization. This is patience. This is war.\"*  \n",
    "— The Colonel, Year 20 of the Siege\n",
    "\n",
    "---\n",
    "\n",
    "## The Core Algorithm\n",
    "\n",
    "**Gradient descent** is the workhorse of machine learning optimization. It's beautifully simple:\n",
    "\n",
    "1. Start somewhere\n",
    "2. Compute the gradient (which way is uphill?)\n",
    "3. Take a step in the opposite direction (downhill)\n",
    "4. Repeat until you reach a minimum\n",
    "\n",
    "The update rule:\n",
    "\n",
    "$$\\theta_{\\text{new}} = \\theta_{\\text{old}} - \\alpha \\cdot \\nabla L(\\theta)$$\n",
    "\n",
    "where:\n",
    "- $\\theta$ = parameters (the knobs we're tuning)\n",
    "- $\\alpha$ = learning rate (step size)\n",
    "- $\\nabla L$ = gradient of loss (points uphill)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lesson, you will:\n",
    "1. Implement gradient descent from scratch\n",
    "2. Understand the role of the learning rate\n",
    "3. Visualize the optimization process\n",
    "4. Diagnose common problems: too large/small learning rate, local minima\n",
    "5. Connect gradient descent to the Colonel's siege strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Nice plotting defaults\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Colab-ready data loading\n",
    "BASE_URL = \"https://raw.githubusercontent.com/buildLittleWorlds/ml-math-with-densworld/main/data/\"\n",
    "\n",
    "# Load the siege data\n",
    "siege = pd.read_csv(BASE_URL + \"siege_progress.csv\")\n",
    "stratagem = pd.read_csv(BASE_URL + \"stratagem_details.csv\")\n",
    "expedition = pd.read_csv(BASE_URL + \"expedition_outcomes.csv\")\n",
    "\n",
    "print(f\"Loaded {len(siege)} months of siege records\")\n",
    "print(f\"Loaded {len(stratagem)} stratagem attempts\")\n",
    "print(f\"Loaded {len(expedition)} expedition records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Part 1: The Simplest Gradient Descent\n",
    "\n",
    "Let's start with a simple 1D example. We want to minimize:\n",
    "\n",
    "$$L(x) = (x - 5)^2$$\n",
    "\n",
    "The minimum is at $x = 5$ (where the loss is zero). The gradient is:\n",
    "\n",
    "$$\\frac{dL}{dx} = 2(x - 5)$$\n",
    "\n",
    "Let's watch gradient descent find the minimum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_1d(x):\n",
    "    \"\"\"Simple quadratic loss function.\"\"\"\n",
    "    return (x - 5)**2\n",
    "\n",
    "def gradient_1d(x):\n",
    "    \"\"\"Gradient of the loss function.\"\"\"\n",
    "    return 2 * (x - 5)\n",
    "\n",
    "def gradient_descent_1d(start, learning_rate, num_steps):\n",
    "    \"\"\"\n",
    "    Perform gradient descent in 1D.\n",
    "    \n",
    "    Returns:\n",
    "        path: list of x values visited\n",
    "        losses: list of loss values at each step\n",
    "    \"\"\"\n",
    "    x = start\n",
    "    path = [x]\n",
    "    losses = [loss_1d(x)]\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        grad = gradient_1d(x)\n",
    "        x = x - learning_rate * grad  # The key update!\n",
    "        path.append(x)\n",
    "        losses.append(loss_1d(x))\n",
    "    \n",
    "    return path, losses\n",
    "\n",
    "# Run gradient descent\n",
    "start = 0\n",
    "learning_rate = 0.1\n",
    "num_steps = 30\n",
    "\n",
    "path, losses = gradient_descent_1d(start, learning_rate, num_steps)\n",
    "\n",
    "# Display first few steps\n",
    "print(\"Gradient Descent Trace:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Step':>6} | {'x':>10} | {'Loss':>12} | {'Gradient':>12}\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(min(10, len(path))):\n",
    "    grad = gradient_1d(path[i])\n",
    "    print(f\"{i:>6} | {path[i]:>10.4f} | {losses[i]:>12.4f} | {grad:>12.4f}\")\n",
    "print(f\"{'...':>6}\")\n",
    "print(f\"{len(path)-1:>6} | {path[-1]:>10.4f} | {losses[-1]:>12.4f} | {gradient_1d(path[-1]):>12.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the gradient descent process\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Show path on loss function\n",
    "x_range = np.linspace(-2, 10, 200)\n",
    "y_range = [loss_1d(x) for x in x_range]\n",
    "\n",
    "axes[0].plot(x_range, y_range, 'b-', linewidth=2, label='Loss function')\n",
    "axes[0].plot(path, losses, 'ro-', markersize=6, linewidth=1.5, label='Gradient descent path')\n",
    "axes[0].plot(path[0], losses[0], 'gs', markersize=12, label='Start')\n",
    "axes[0].plot(path[-1], losses[-1], 'g*', markersize=15, label='End')\n",
    "axes[0].axvline(5, color='green', linestyle='--', alpha=0.5, label='True minimum')\n",
    "axes[0].set_xlabel('x', fontsize=11)\n",
    "axes[0].set_ylabel('Loss', fontsize=11)\n",
    "axes[0].set_title('Gradient Descent on a Quadratic Loss', fontsize=12)\n",
    "axes[0].legend()\n",
    "\n",
    "# Right: Show loss over steps\n",
    "axes[1].plot(losses, 'b-', linewidth=2)\n",
    "axes[1].set_xlabel('Step', fontsize=11)\n",
    "axes[1].set_ylabel('Loss', fontsize=11)\n",
    "axes[1].set_title('Loss Over Time (Convergence Curve)', fontsize=12)\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Started at x = {start}, ended at x = {path[-1]:.6f}\")\n",
    "print(f\"True minimum is at x = 5\")\n",
    "print(f\"Final loss: {losses[-1]:.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Part 2: The Learning Rate — The Colonel's Courage\n",
    "\n",
    "*\"How bold should each step be? Too timid, and I grow old before reaching my goal. Too bold, and I overshoot, oscillating wildly, perhaps never converging. The learning rate is the measure of my courage—or my recklessness.\"*  \n",
    "— The Colonel\n",
    "\n",
    "The **learning rate** ($\\alpha$) controls how big each step is:\n",
    "- **Too small**: Slow convergence, might take forever\n",
    "- **Too large**: Overshooting, oscillation, might diverge\n",
    "- **Just right**: Fast and stable convergence\n",
    "\n",
    "Let's see these three regimes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different learning rates\n",
    "learning_rates = [0.01, 0.1, 0.5, 0.95, 1.05]\n",
    "labels = ['Too small (0.01)', 'Good (0.1)', 'Faster (0.5)', 'Edge of stability (0.95)', 'Diverges (1.05)']\n",
    "colors = ['blue', 'green', 'orange', 'red', 'purple']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Paths on loss function\n",
    "x_range = np.linspace(-5, 15, 200)\n",
    "y_range = [loss_1d(x) for x in x_range]\n",
    "axes[0].plot(x_range, y_range, 'k-', linewidth=2, alpha=0.3, label='Loss')\n",
    "\n",
    "# Right: Convergence curves\n",
    "for lr, label, color in zip(learning_rates, labels, colors):\n",
    "    path, losses = gradient_descent_1d(start=0, learning_rate=lr, num_steps=40)\n",
    "    \n",
    "    # Clip for visualization if diverging\n",
    "    losses_clipped = np.clip(losses, 0, 200)\n",
    "    path_clipped = np.clip(path, -5, 15)\n",
    "    \n",
    "    axes[0].plot(path_clipped[:20], losses_clipped[:20], 'o-', color=color, \n",
    "                markersize=4, linewidth=1.5, alpha=0.7, label=label)\n",
    "    axes[1].plot(losses_clipped, color=color, linewidth=2, label=label)\n",
    "\n",
    "axes[0].axvline(5, color='green', linestyle='--', alpha=0.5)\n",
    "axes[0].set_xlabel('x', fontsize=11)\n",
    "axes[0].set_ylabel('Loss', fontsize=11)\n",
    "axes[0].set_title('Effect of Learning Rate on Optimization Path', fontsize=12)\n",
    "axes[0].legend(fontsize=9)\n",
    "axes[0].set_ylim(-5, 100)\n",
    "\n",
    "axes[1].set_xlabel('Step', fontsize=11)\n",
    "axes[1].set_ylabel('Loss', fontsize=11)\n",
    "axes[1].set_title('Convergence Curves for Different Learning Rates', fontsize=12)\n",
    "axes[1].legend(fontsize=9)\n",
    "axes[1].set_ylim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observations:\")\n",
    "print(\"- Learning rate 0.01: Converges, but very slowly\")\n",
    "print(\"- Learning rate 0.1: Good balance of speed and stability\")\n",
    "print(\"- Learning rate 0.5: Faster, still stable\")\n",
    "print(\"- Learning rate 0.95: Oscillates but eventually converges\")\n",
    "print(\"- Learning rate 1.05: DIVERGES! Loss explodes instead of decreasing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Part 3: Gradient Descent in 2D — The Colonel's Multi-Front War\n",
    "\n",
    "Now let's apply gradient descent to a 2D problem, where we optimize two parameters simultaneously.\n",
    "\n",
    "*\"I do not fight on a single front. Personnel and supplies, timing and tactics—all must be optimized together. The gradient tells me how to adjust each, and I step forward on all fronts at once.\"*  \n",
    "— The Colonel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_2d(x, y):\n",
    "    \"\"\"2D loss function: bowl-shaped with minimum at (3, 2).\"\"\"\n",
    "    return (x - 3)**2 + 2*(y - 2)**2\n",
    "\n",
    "def gradient_2d(x, y):\n",
    "    \"\"\"Gradient of the 2D loss function.\"\"\"\n",
    "    dL_dx = 2 * (x - 3)\n",
    "    dL_dy = 4 * (y - 2)\n",
    "    return np.array([dL_dx, dL_dy])\n",
    "\n",
    "def gradient_descent_2d(start, learning_rate, num_steps):\n",
    "    \"\"\"\n",
    "    Perform gradient descent in 2D.\n",
    "    \"\"\"\n",
    "    pos = np.array(start, dtype=float)\n",
    "    path = [pos.copy()]\n",
    "    losses = [loss_2d(pos[0], pos[1])]\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        grad = gradient_2d(pos[0], pos[1])\n",
    "        pos = pos - learning_rate * grad\n",
    "        path.append(pos.copy())\n",
    "        losses.append(loss_2d(pos[0], pos[1]))\n",
    "    \n",
    "    return np.array(path), losses\n",
    "\n",
    "# Run gradient descent from different starting points\n",
    "starts = [(-2, -1), (8, 5), (0, 6), (6, -1)]\n",
    "colors = ['blue', 'red', 'green', 'purple']\n",
    "\n",
    "# Create meshgrid for visualization\n",
    "x_range = np.linspace(-3, 9, 100)\n",
    "y_range = np.linspace(-2, 7, 100)\n",
    "X, Y = np.meshgrid(x_range, y_range)\n",
    "Z = loss_2d(X, Y)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Left: Contour plot with paths\n",
    "contour = axes[0].contour(X, Y, Z, levels=20, cmap='viridis')\n",
    "axes[0].clabel(contour, inline=True, fontsize=8)\n",
    "\n",
    "for start, color in zip(starts, colors):\n",
    "    path, losses = gradient_descent_2d(start, learning_rate=0.15, num_steps=30)\n",
    "    axes[0].plot(path[:, 0], path[:, 1], 'o-', color=color, \n",
    "                markersize=4, linewidth=1.5, label=f'Start: {start}')\n",
    "    axes[0].plot(path[0, 0], path[0, 1], 's', color=color, markersize=10)\n",
    "    axes[0].plot(path[-1, 0], path[-1, 1], '*', color=color, markersize=15)\n",
    "\n",
    "axes[0].plot(3, 2, 'k*', markersize=20, label='Minimum (3, 2)')\n",
    "axes[0].set_xlabel('x (Personnel)', fontsize=11)\n",
    "axes[0].set_ylabel('y (Supplies)', fontsize=11)\n",
    "axes[0].set_title('Gradient Descent Paths in 2D', fontsize=12)\n",
    "axes[0].legend(fontsize=9)\n",
    "\n",
    "# Right: Convergence curves\n",
    "for start, color in zip(starts, colors):\n",
    "    path, losses = gradient_descent_2d(start, learning_rate=0.15, num_steps=30)\n",
    "    axes[1].plot(losses, color=color, linewidth=2, label=f'Start: {start}')\n",
    "\n",
    "axes[1].set_xlabel('Step', fontsize=11)\n",
    "axes[1].set_ylabel('Loss', fontsize=11)\n",
    "axes[1].set_title('Convergence Curves', fontsize=12)\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Part 4: The Colonel's Real Data — Fitting a Model\n",
    "\n",
    "Now let's use gradient descent to fit a real model to the Colonel's stratagem data. We'll predict `progress_delta` from the stratagem features.\n",
    "\n",
    "For linear regression, we're minimizing the **mean squared error**:\n",
    "\n",
    "$$L(\\mathbf{w}) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\mathbf{w} \\cdot \\mathbf{x}_i)^2$$\n",
    "\n",
    "The gradient with respect to weights $\\mathbf{w}$ is:\n",
    "\n",
    "$$\\nabla L = -\\frac{2}{n} \\sum_{i=1}^{n} (y_i - \\mathbf{w} \\cdot \\mathbf{x}_i) \\mathbf{x}_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for linear regression\n",
    "features = ['personnel_committed', 'supply_cost', 'risk_level', 'colonel_confidence']\n",
    "\n",
    "# Normalize features for stable gradient descent\n",
    "X = stratagem[features].values\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X_norm = (X - X_mean) / X_std\n",
    "\n",
    "# Add bias term\n",
    "X_norm = np.column_stack([np.ones(len(X_norm)), X_norm])\n",
    "\n",
    "y = stratagem['progress_delta'].values\n",
    "\n",
    "print(f\"Data shape: {X_norm.shape}\")\n",
    "print(f\"Features: ['bias'] + {features}\")\n",
    "print(f\"Target: progress_delta (mean={y.mean():.4f}, std={y.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(w, X, y):\n",
    "    \"\"\"Mean squared error loss.\"\"\"\n",
    "    predictions = X @ w\n",
    "    errors = y - predictions\n",
    "    return np.mean(errors**2)\n",
    "\n",
    "def mse_gradient(w, X, y):\n",
    "    \"\"\"Gradient of MSE with respect to weights.\"\"\"\n",
    "    predictions = X @ w\n",
    "    errors = y - predictions\n",
    "    gradient = -2 * X.T @ errors / len(y)\n",
    "    return gradient\n",
    "\n",
    "def gradient_descent_linear(X, y, learning_rate, num_steps):\n",
    "    \"\"\"\n",
    "    Perform gradient descent for linear regression.\n",
    "    \"\"\"\n",
    "    # Initialize weights randomly\n",
    "    w = np.random.randn(X.shape[1]) * 0.01\n",
    "    \n",
    "    losses = [mse_loss(w, X, y)]\n",
    "    weights_history = [w.copy()]\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        grad = mse_gradient(w, X, y)\n",
    "        w = w - learning_rate * grad\n",
    "        losses.append(mse_loss(w, X, y))\n",
    "        weights_history.append(w.copy())\n",
    "    \n",
    "    return w, losses, weights_history\n",
    "\n",
    "# Run gradient descent\n",
    "learning_rate = 0.1\n",
    "num_steps = 200\n",
    "\n",
    "w_final, losses, weights_history = gradient_descent_linear(X_norm, y, learning_rate, num_steps)\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Initial loss: {losses[0]:.6f}\")\n",
    "print(f\"Final loss: {losses[-1]:.6f}\")\n",
    "print(f\"Loss reduction: {(1 - losses[-1]/losses[0])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Loss curve\n",
    "axes[0].plot(losses, 'b-', linewidth=2)\n",
    "axes[0].set_xlabel('Step', fontsize=11)\n",
    "axes[0].set_ylabel('MSE Loss', fontsize=11)\n",
    "axes[0].set_title('Training Loss Over Time', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Weight evolution\n",
    "weights_history = np.array(weights_history)\n",
    "labels = ['bias'] + features\n",
    "for i, label in enumerate(labels):\n",
    "    axes[1].plot(weights_history[:, i], linewidth=2, label=label)\n",
    "\n",
    "axes[1].set_xlabel('Step', fontsize=11)\n",
    "axes[1].set_ylabel('Weight Value', fontsize=11)\n",
    "axes[1].set_title('Weight Evolution During Training', fontsize=12)\n",
    "axes[1].legend(fontsize=9)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display final weights\n",
    "print(\"\\nFinal Weights (The Colonel's Learned Strategy):\")\n",
    "print(\"=\" * 50)\n",
    "for label, weight in zip(labels, w_final):\n",
    "    direction = \"↑ helps\" if weight > 0 else \"↓ hurts\"\n",
    "    print(f\"{label:25}: {weight:>10.4f}  ({direction})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Part 5: Batch vs Stochastic Gradient Descent\n",
    "\n",
    "So far, we've used **batch gradient descent**—computing the gradient using *all* data points at each step.\n",
    "\n",
    "In practice, especially with large datasets, we often use:\n",
    "\n",
    "1. **Stochastic Gradient Descent (SGD)**: Use one random sample per step\n",
    "2. **Mini-batch Gradient Descent**: Use a small random batch per step\n",
    "\n",
    "*\"I cannot test every stratagem against the entire history of the siege. Instead, I sample—I try one approach, observe the result, and adjust. This is noisier, but faster. The gradient I estimate is imperfect, but good enough to make progress.\"*  \n",
    "— The Colonel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_linear(X, y, learning_rate, num_epochs, batch_size=1):\n",
    "    \"\"\"\n",
    "    Stochastic/Mini-batch gradient descent for linear regression.\n",
    "    \"\"\"\n",
    "    n_samples = len(y)\n",
    "    w = np.random.randn(X.shape[1]) * 0.01\n",
    "    \n",
    "    losses = [mse_loss(w, X, y)]\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle data\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        \n",
    "        for start_idx in range(0, n_samples, batch_size):\n",
    "            batch_indices = indices[start_idx:start_idx + batch_size]\n",
    "            X_batch = X[batch_indices]\n",
    "            y_batch = y[batch_indices]\n",
    "            \n",
    "            # Compute gradient on batch\n",
    "            grad = mse_gradient(w, X_batch, y_batch)\n",
    "            w = w - learning_rate * grad\n",
    "        \n",
    "        losses.append(mse_loss(w, X, y))\n",
    "    \n",
    "    return w, losses\n",
    "\n",
    "# Compare batch sizes\n",
    "batch_sizes = [1, 8, 32, len(y)]  # SGD, mini-batch, mini-batch, full batch\n",
    "labels = ['SGD (batch=1)', 'Mini-batch (8)', 'Mini-batch (32)', 'Full Batch']\n",
    "colors = ['red', 'orange', 'blue', 'green']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for batch_size, label, color in zip(batch_sizes, labels, colors):\n",
    "    w, losses = sgd_linear(X_norm, y, learning_rate=0.05, \n",
    "                           num_epochs=50, batch_size=batch_size)\n",
    "    ax.plot(losses, color=color, linewidth=2, label=label, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Epoch', fontsize=11)\n",
    "ax.set_ylabel('MSE Loss', fontsize=11)\n",
    "ax.set_title('Comparison of Batch Sizes\\n(Noise vs Speed Trade-off)', fontsize=12)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observations:\")\n",
    "print(\"- SGD (batch=1): Noisy but can escape local minima\")\n",
    "print(\"- Mini-batch: Balance between noise and stability\")\n",
    "print(\"- Full batch: Smooth but may be slower on large data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Part 6: Common Pitfalls\n",
    "\n",
    "### Pitfall 1: Learning Rate Too Large — Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate divergence with large learning rate\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "for lr in [0.01, 0.1, 0.5, 1.0]:\n",
    "    try:\n",
    "        w, losses, _ = gradient_descent_linear(X_norm, y, learning_rate=lr, num_steps=100)\n",
    "        losses_clipped = np.clip(losses, 0, 1)  # Clip for visualization\n",
    "        ax.plot(losses_clipped, linewidth=2, label=f'LR = {lr}')\n",
    "    except:\n",
    "        print(f\"LR = {lr} diverged!\")\n",
    "\n",
    "ax.set_xlabel('Step', fontsize=11)\n",
    "ax.set_ylabel('MSE Loss (clipped)', fontsize=11)\n",
    "ax.set_title('Learning Rate Effect: Too Large = Divergence', fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### Pitfall 2: Local Minima and Saddle Points\n",
    "\n",
    "In non-convex landscapes, gradient descent can get stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-convex loss function with local minima\n",
    "def non_convex_loss(x):\n",
    "    return x**4 - 4*x**2 + x + 3\n",
    "\n",
    "def non_convex_gradient(x):\n",
    "    return 4*x**3 - 8*x + 1\n",
    "\n",
    "# Visualize\n",
    "x_range = np.linspace(-2.5, 2.5, 200)\n",
    "y_range = [non_convex_loss(x) for x in x_range]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Loss landscape\n",
    "axes[0].plot(x_range, y_range, 'b-', linewidth=2)\n",
    "\n",
    "# Run GD from different starting points\n",
    "starts = [-2.0, -0.5, 0.5, 2.0]\n",
    "colors = ['red', 'green', 'orange', 'purple']\n",
    "\n",
    "for start, color in zip(starts, colors):\n",
    "    x = start\n",
    "    path = [x]\n",
    "    for _ in range(50):\n",
    "        grad = non_convex_gradient(x)\n",
    "        x = x - 0.01 * grad\n",
    "        path.append(x)\n",
    "    \n",
    "    y_path = [non_convex_loss(p) for p in path]\n",
    "    axes[0].plot(path, y_path, 'o-', color=color, markersize=3, \n",
    "                linewidth=1.5, alpha=0.7, label=f'Start: {start}')\n",
    "\n",
    "axes[0].set_xlabel('x', fontsize=11)\n",
    "axes[0].set_ylabel('Loss', fontsize=11)\n",
    "axes[0].set_title('Non-Convex Landscape: Local Minima Trap', fontsize=12)\n",
    "axes[0].legend()\n",
    "\n",
    "# Right: Gradient showing multiple zeros\n",
    "grad_range = [non_convex_gradient(x) for x in x_range]\n",
    "axes[1].plot(x_range, grad_range, 'r-', linewidth=2)\n",
    "axes[1].axhline(0, color='black', linestyle='--')\n",
    "axes[1].set_xlabel('x', fontsize=11)\n",
    "axes[1].set_ylabel('Gradient', fontsize=11)\n",
    "axes[1].set_title('Gradient: Multiple Zeros = Multiple Critical Points', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Starting from x = -2 leads to a local minimum.\")\n",
    "print(\"Starting from x = 2 leads to a different (global) minimum.\")\n",
    "print(\"\\nIn neural networks, this is why initialization and momentum matter!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Part 7: The Colonel's Step Size Record\n",
    "\n",
    "The stratagem data includes the Colonel's `step_size`—how aggressive each move was. Let's analyze how step size affected outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationship between step_size and outcomes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Step size vs progress\n",
    "colors_map = {'success': 'green', 'partial': 'orange', 'failure': 'gray', 'disaster': 'red'}\n",
    "for outcome in colors_map:\n",
    "    mask = stratagem['outcome_category'] == outcome\n",
    "    axes[0].scatter(stratagem.loc[mask, 'step_size'], \n",
    "                   stratagem.loc[mask, 'progress_delta'],\n",
    "                   c=colors_map[outcome], label=outcome, alpha=0.6, s=40)\n",
    "\n",
    "axes[0].axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0].set_xlabel('Step Size (Colonel\\'s Learning Rate)', fontsize=11)\n",
    "axes[0].set_ylabel('Progress Delta', fontsize=11)\n",
    "axes[0].set_title('Step Size vs Outcome', fontsize=12)\n",
    "axes[0].legend()\n",
    "\n",
    "# Right: Distribution of step sizes by outcome\n",
    "step_by_outcome = stratagem.groupby('outcome_category')['step_size'].agg(['mean', 'std', 'count'])\n",
    "step_by_outcome = step_by_outcome.loc[['success', 'partial', 'failure', 'disaster']]\n",
    "\n",
    "axes[1].bar(step_by_outcome.index, step_by_outcome['mean'], \n",
    "           yerr=step_by_outcome['std'], capsize=5,\n",
    "           color=[colors_map[o] for o in step_by_outcome.index], alpha=0.7)\n",
    "axes[1].set_xlabel('Outcome Category', fontsize=11)\n",
    "axes[1].set_ylabel('Average Step Size', fontsize=11)\n",
    "axes[1].set_title('Average Step Size by Outcome', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStep Size Statistics by Outcome:\")\n",
    "print(step_by_outcome.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Implement Momentum\n",
    "\n",
    "Momentum helps gradient descent move faster and escape local minima. The update becomes:\n",
    "\n",
    "$$v_t = \\beta v_{t-1} + \\nabla L$$\n",
    "$$\\theta_t = \\theta_{t-1} - \\alpha v_t$$\n",
    "\n",
    "where $\\beta$ is the momentum coefficient (typically 0.9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Implement gradient descent with momentum\n",
    "\n",
    "def gradient_descent_momentum(X, y, learning_rate, momentum, num_steps):\n",
    "    \"\"\"\n",
    "    Gradient descent with momentum for linear regression.\n",
    "    \"\"\"\n",
    "    w = np.random.randn(X.shape[1]) * 0.01\n",
    "    v = np.zeros_like(w)  # Velocity\n",
    "    \n",
    "    losses = [mse_loss(w, X, y)]\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        grad = mse_gradient(w, X, y)\n",
    "        v = momentum * v + grad  # Update velocity\n",
    "        w = w - learning_rate * v  # Update weights using velocity\n",
    "        losses.append(mse_loss(w, X, y))\n",
    "    \n",
    "    return w, losses\n",
    "\n",
    "# Compare with and without momentum\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Without momentum\n",
    "w1, losses1, _ = gradient_descent_linear(X_norm, y, learning_rate=0.05, num_steps=100)\n",
    "ax.plot(losses1, 'b-', linewidth=2, label='No momentum')\n",
    "\n",
    "# With momentum\n",
    "w2, losses2 = gradient_descent_momentum(X_norm, y, learning_rate=0.05, momentum=0.9, num_steps=100)\n",
    "ax.plot(losses2, 'r-', linewidth=2, label='With momentum (0.9)')\n",
    "\n",
    "ax.set_xlabel('Step', fontsize=11)\n",
    "ax.set_ylabel('MSE Loss', fontsize=11)\n",
    "ax.set_title('Effect of Momentum on Convergence', fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Without momentum - Final loss: {losses1[-1]:.6f}\")\n",
    "print(f\"With momentum - Final loss: {losses2[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "### Exercise 2: Learning Rate Schedule\n",
    "\n",
    "Sometimes it helps to decrease the learning rate over time. Implement a learning rate schedule that starts large and decays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Learning rate scheduling\n",
    "\n",
    "def gradient_descent_lr_decay(X, y, initial_lr, decay_rate, num_steps):\n",
    "    \"\"\"\n",
    "    Gradient descent with exponential learning rate decay.\n",
    "    lr(t) = initial_lr * exp(-decay_rate * t)\n",
    "    \"\"\"\n",
    "    w = np.random.randn(X.shape[1]) * 0.01\n",
    "    \n",
    "    losses = [mse_loss(w, X, y)]\n",
    "    learning_rates = [initial_lr]\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # Decay learning rate\n",
    "        lr = initial_lr * np.exp(-decay_rate * step)\n",
    "        learning_rates.append(lr)\n",
    "        \n",
    "        grad = mse_gradient(w, X, y)\n",
    "        w = w - lr * grad\n",
    "        losses.append(mse_loss(w, X, y))\n",
    "    \n",
    "    return w, losses, learning_rates\n",
    "\n",
    "# Compare constant vs decaying learning rate\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Constant LR\n",
    "w1, losses1, _ = gradient_descent_linear(X_norm, y, learning_rate=0.1, num_steps=100)\n",
    "\n",
    "# Decaying LR\n",
    "w2, losses2, lrs = gradient_descent_lr_decay(X_norm, y, initial_lr=0.3, decay_rate=0.03, num_steps=100)\n",
    "\n",
    "axes[0].plot(losses1, 'b-', linewidth=2, label='Constant LR = 0.1')\n",
    "axes[0].plot(losses2, 'r-', linewidth=2, label='Decaying LR (0.3 → 0.015)')\n",
    "axes[0].set_xlabel('Step', fontsize=11)\n",
    "axes[0].set_ylabel('MSE Loss', fontsize=11)\n",
    "axes[0].set_title('Learning Rate Schedule Effect', fontsize=12)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(lrs, 'r-', linewidth=2)\n",
    "axes[1].set_xlabel('Step', fontsize=11)\n",
    "axes[1].set_ylabel('Learning Rate', fontsize=11)\n",
    "axes[1].set_title('Decaying Learning Rate Schedule', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "### Exercise 3: Apply GD to Expedition Data\n",
    "\n",
    "Fit a linear model to predict expedition `profit_loss` from the features in the expedition data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Expedition data\n",
    "\n",
    "# Prepare expedition features\n",
    "exp_features = ['party_size', 'initial_supply_score', 'risk_tolerance', 'weather_stability']\n",
    "\n",
    "X_exp = expedition[exp_features].values\n",
    "X_exp_mean = X_exp.mean(axis=0)\n",
    "X_exp_std = X_exp.std(axis=0)\n",
    "X_exp_norm = (X_exp - X_exp_mean) / X_exp_std\n",
    "X_exp_norm = np.column_stack([np.ones(len(X_exp_norm)), X_exp_norm])\n",
    "\n",
    "y_exp = expedition['profit_loss'].values\n",
    "\n",
    "# Train model\n",
    "w_exp, losses_exp, _ = gradient_descent_linear(X_exp_norm, y_exp, \n",
    "                                                learning_rate=0.1, num_steps=200)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(losses_exp, 'b-', linewidth=2)\n",
    "axes[0].set_xlabel('Step', fontsize=11)\n",
    "axes[0].set_ylabel('MSE Loss', fontsize=11)\n",
    "axes[0].set_title('Training Loss for Expedition Profit Prediction', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Predictions vs actual\n",
    "predictions = X_exp_norm @ w_exp\n",
    "axes[1].scatter(y_exp, predictions, alpha=0.5, s=30)\n",
    "axes[1].plot([y_exp.min(), y_exp.max()], [y_exp.min(), y_exp.max()], 'r--', linewidth=2)\n",
    "axes[1].set_xlabel('Actual Profit/Loss', fontsize=11)\n",
    "axes[1].set_ylabel('Predicted Profit/Loss', fontsize=11)\n",
    "axes[1].set_title('Predictions vs Actual', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show coefficients\n",
    "print(\"\\nLearned Coefficients:\")\n",
    "for label, weight in zip(['bias'] + exp_features, w_exp):\n",
    "    print(f\"{label:25}: {weight:>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "### Exercise 4: Gradient Descent Visualization Animation\n",
    "\n",
    "Create an animated visualization of gradient descent on a 2D surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Animated gradient descent (static frames for notebook)\n",
    "\n",
    "# Generate path\n",
    "path, losses = gradient_descent_2d(start=(-2, 5), learning_rate=0.1, num_steps=40)\n",
    "\n",
    "# Create multi-frame visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "steps_to_show = [0, 5, 10, 20, 30, 40]\n",
    "\n",
    "for ax, step in zip(axes, steps_to_show):\n",
    "    # Plot contours\n",
    "    contour = ax.contour(X, Y, Z, levels=15, cmap='viridis', alpha=0.5)\n",
    "    \n",
    "    # Plot path up to this step\n",
    "    ax.plot(path[:step+1, 0], path[:step+1, 1], 'ro-', markersize=4, linewidth=1.5)\n",
    "    \n",
    "    # Mark current position\n",
    "    ax.plot(path[step, 0], path[step, 1], 'r*', markersize=15)\n",
    "    \n",
    "    # Mark minimum\n",
    "    ax.plot(3, 2, 'g*', markersize=15)\n",
    "    \n",
    "    ax.set_title(f'Step {step}\\nLoss: {losses[step]:.4f}', fontsize=11)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_xlim(-3, 9)\n",
    "    ax.set_ylim(-2, 7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Concept | Key Insight | Colonel's Siege Example |\n",
    "|---------|-------------|------------------------|\n",
    "| **Gradient Descent** | Iteratively move opposite to gradient | Take steps toward the Tower based on what reduces loss |\n",
    "| **Learning Rate** | Step size—too small = slow, too large = unstable | How bold is each strategic adjustment? |\n",
    "| **Convergence** | Loss decreases over iterations | Progress accumulates over months and years |\n",
    "| **Local Minima** | Getting stuck in suboptimal solutions | Settling for partial success when better exists |\n",
    "| **SGD** | Use random samples for faster, noisier updates | Test one stratagem, adjust, repeat |\n",
    "| **Momentum** | Accumulate velocity to escape local minima | Build on past successes; don't overcorrect |\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Gradient descent is simple**: Move opposite to gradient, repeat.\n",
    "\n",
    "2. **Learning rate is crucial**: Too small = slow; too large = unstable.\n",
    "\n",
    "3. **SGD trades accuracy for speed**: Use small batches for faster updates.\n",
    "\n",
    "4. **Local minima are real**: Initialization and momentum help escape them.\n",
    "\n",
    "5. **The algorithm is the same everywhere**: From linear regression to deep learning, it's all gradient descent.\n",
    "\n",
    "---\n",
    "\n",
    "## Next Lesson\n",
    "\n",
    "In **Lesson 4: The Chain Rule and Backpropagation**, we'll see how gradients are computed efficiently for complex, nested functions—like neural networks. This is the magic that makes deep learning possible.\n",
    "\n",
    "*\"I understand now how to walk downhill. But the landscape is not simple—it is layers upon layers, each stratagem affecting the next in ways I cannot directly observe. To trace the sensitivity through this chain of causation, I need the chain rule.\"*  \n",
    "— The Colonel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
