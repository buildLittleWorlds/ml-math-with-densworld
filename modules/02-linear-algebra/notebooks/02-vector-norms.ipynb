{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/buildLittleWorlds/ml-math-with-densworld/blob/main/modules/02-linear-algebra/notebooks/02-vector-norms.ipynb)\n",
    "\n",
    "# Lesson 2: Vector Norms — Measuring Distance in Different Ways\n",
    "\n",
    "*\"The shortest path between two points depends on how you're allowed to travel. In the Dens, where tunnels twist and branch, the straight line is a fantasy. The Pickbox Man measures distance in footsteps along corridors. Vagabu Olt measures it as the crow flies—through solid rock, if necessary.\"*  \n",
    "— The Pickbox Man, tunnel surveyor\n",
    "\n",
    "---\n",
    "\n",
    "## The Core Problem\n",
    "\n",
    "In Lesson 1, we measured distance between creatures using the **Euclidean distance**—the straight-line path through feature space. But this isn't the only way to measure \"how different\" two things are.\n",
    "\n",
    "Consider two mapmakers surveying the Dens:\n",
    "- **Vagabu Olt** thinks in straight lines (Euclidean, L2)\n",
    "- **The Pickbox Man** navigates through tunnels (Manhattan, L1)\n",
    "\n",
    "Their different perspectives lead to **different distance measurements**—and in machine learning, the choice of distance metric has real consequences for classification, clustering, and regularization.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lesson, you will:\n",
    "1. Calculate L1 (Manhattan) and L2 (Euclidean) norms and distances\n",
    "2. Understand when each norm is more appropriate\n",
    "3. See how norm choice affects nearest-neighbor classification\n",
    "4. Connect norms to regularization in machine learning (L1 → Lasso, L2 → Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Nice plotting defaults\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Colab-ready data loading\n",
    "BASE_URL = \"https://raw.githubusercontent.com/buildLittleWorlds/ml-math-with-densworld/main/data/\"\n",
    "\n",
    "# Load our datasets\n",
    "creature_vectors = pd.read_csv(BASE_URL + \"creature_vectors.csv\")\n",
    "creature_similarity = pd.read_csv(BASE_URL + \"creature_similarity.csv\")\n",
    "dens_boundary = pd.read_csv(BASE_URL + \"dens_boundary_observations.csv\")\n",
    "\n",
    "print(f\"Loaded {len(creature_vectors)} creatures with behavioral/habitat vectors\")\n",
    "print(f\"Loaded {len(creature_similarity)} pairwise similarity calculations\")\n",
    "print(f\"Loaded {len(dens_boundary)} boundary observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Part 1: Two Ways to Measure — L1 vs L2\n",
    "\n",
    "### The Euclidean Norm (L2)\n",
    "\n",
    "The **L2 norm** measures the straight-line distance—\"as the crow flies\":\n",
    "\n",
    "$$\\|\\mathbf{v}\\|_2 = \\sqrt{\\sum_{i=1}^{n} v_i^2}$$\n",
    "\n",
    "For the distance between two vectors:\n",
    "$$d_{L2}(\\mathbf{a}, \\mathbf{b}) = \\sqrt{\\sum_{i=1}^{n} (a_i - b_i)^2}$$\n",
    "\n",
    "### The Manhattan Norm (L1)\n",
    "\n",
    "The **L1 norm** measures distance along axes—like walking a city grid:\n",
    "\n",
    "$$\\|\\mathbf{v}\\|_1 = \\sum_{i=1}^{n} |v_i|$$\n",
    "\n",
    "For the distance between two vectors:\n",
    "$$d_{L1}(\\mathbf{a}, \\mathbf{b}) = \\sum_{i=1}^{n} |a_i - b_i|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison of L1 vs L2 distance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Define two points\n",
    "point_a = np.array([1, 1])\n",
    "point_b = np.array([4, 5])\n",
    "\n",
    "# L2 (Euclidean) - straight line\n",
    "ax = axes[0]\n",
    "ax.scatter(*point_a, s=150, c='steelblue', zorder=5, label='Point A (1,1)')\n",
    "ax.scatter(*point_b, s=150, c='coral', zorder=5, label='Point B (4,5)')\n",
    "ax.plot([point_a[0], point_b[0]], [point_a[1], point_b[1]], 'g-', linewidth=3, \n",
    "        label=f'L2 distance = {np.linalg.norm(point_b - point_a):.2f}')\n",
    "ax.set_xlim(0, 6)\n",
    "ax.set_ylim(0, 6)\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title('L2 (Euclidean): \"As the Crow Flies\"\\nVagabu Olt\\'s View', fontsize=13)\n",
    "ax.legend(fontsize=10)\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# L1 (Manhattan) - along grid\n",
    "ax = axes[1]\n",
    "ax.scatter(*point_a, s=150, c='steelblue', zorder=5, label='Point A (1,1)')\n",
    "ax.scatter(*point_b, s=150, c='coral', zorder=5, label='Point B (4,5)')\n",
    "# Draw the L1 path (horizontal then vertical)\n",
    "ax.plot([point_a[0], point_b[0]], [point_a[1], point_a[1]], 'purple', linewidth=3)\n",
    "ax.plot([point_b[0], point_b[0]], [point_a[1], point_b[1]], 'purple', linewidth=3,\n",
    "        label=f'L1 distance = {np.sum(np.abs(point_b - point_a)):.2f}')\n",
    "ax.set_xlim(0, 6)\n",
    "ax.set_ylim(0, 6)\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title('L1 (Manhattan): \"Through the Tunnels\"\\nThe Pickbox Man\\'s View', fontsize=13)\n",
    "ax.legend(fontsize=10)\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate both distances\n",
    "l2_dist = np.linalg.norm(point_b - point_a)\n",
    "l1_dist = np.sum(np.abs(point_b - point_a))\n",
    "print(f\"L2 (Euclidean) distance: {l2_dist:.4f}\")\n",
    "print(f\"L1 (Manhattan) distance: {l1_dist:.4f}\")\n",
    "print(f\"\\nL1 is always >= L2 (equality only on axis-aligned paths)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Part 2: Unit Circles Under Different Norms\n",
    "\n",
    "A powerful way to understand norms is to visualize their **unit circles**—the set of all points at distance 1 from the origin.\n",
    "\n",
    "- L2 unit circle: The familiar round circle\n",
    "- L1 unit circle: A diamond (rotated square)\n",
    "\n",
    "*\"The Pickbox Man's world is made of diamonds. Every step must be along a tunnel—no cutting corners.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize unit circles for different norms\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "\n",
    "# L2 unit circle (standard circle)\n",
    "x_l2 = np.cos(theta)\n",
    "y_l2 = np.sin(theta)\n",
    "ax.plot(x_l2, y_l2, 'g-', linewidth=3, label='L2 unit circle (Euclidean)')\n",
    "\n",
    "# L1 unit circle (diamond)\n",
    "x_l1 = np.array([1, 0, -1, 0, 1])\n",
    "y_l1 = np.array([0, 1, 0, -1, 0])\n",
    "ax.plot(x_l1, y_l1, 'purple', linewidth=3, label='L1 unit circle (Manhattan)')\n",
    "\n",
    "# L-infinity unit circle (square)\n",
    "x_linf = np.array([1, 1, -1, -1, 1])\n",
    "y_linf = np.array([1, -1, -1, 1, 1])\n",
    "ax.plot(x_linf, y_linf, 'orange', linewidth=3, linestyle='--', label='L∞ unit circle (max norm)')\n",
    "\n",
    "ax.scatter(0, 0, s=100, c='black', zorder=5)\n",
    "ax.set_xlim(-1.5, 1.5)\n",
    "ax.set_ylim(-1.5, 1.5)\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title('Unit Circles Under Different Norms\\n(All points at distance 1 from origin)', fontsize=13)\n",
    "ax.legend(fontsize=11, loc='upper right')\n",
    "ax.set_aspect('equal')\n",
    "ax.axhline(0, color='black', linewidth=0.5)\n",
    "ax.axvline(0, color='black', linewidth=0.5)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key insight: The 'shape' of distance changes with the norm!\")\n",
    "print(\"  - L2: Distance is the same in all directions\")\n",
    "print(\"  - L1: Diagonal directions are 'further' than axis-aligned\")\n",
    "print(\"  - L∞: Only the largest coordinate matters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Part 3: Creature Distances Under Different Norms\n",
    "\n",
    "Let's see how the choice of norm affects creature similarity rankings. Which creatures are \"closest\" to the Witch Creature depends on how we measure distance!\n",
    "\n",
    "*\"The Colonel asks which creatures are most like the Witch Creature, so we know what else lurks in its territory. But 'most like' depends on how you measure.\"*  \n",
    "— Expedition planning notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract behavioral features\n",
    "behavioral_features = ['aggression', 'sociality', 'nocturnality', 'territoriality', 'hunting_strategy']\n",
    "X = creature_vectors[behavioral_features].values\n",
    "names = creature_vectors['common_name'].values\n",
    "\n",
    "# Find Witch Creature index\n",
    "witch_idx = np.where(names == 'Witch Creature')[0][0]\n",
    "witch_vector = X[witch_idx].reshape(1, -1)\n",
    "\n",
    "# Calculate distances using different norms\n",
    "l1_distances = cdist(witch_vector, X, metric='cityblock')[0]\n",
    "l2_distances = cdist(witch_vector, X, metric='euclidean')[0]\n",
    "linf_distances = cdist(witch_vector, X, metric='chebyshev')[0]  # L-infinity\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison = pd.DataFrame({\n",
    "    'creature': names,\n",
    "    'L1_dist': l1_distances,\n",
    "    'L2_dist': l2_distances,\n",
    "    'Linf_dist': linf_distances\n",
    "})\n",
    "\n",
    "# Rank by each distance\n",
    "comparison['L1_rank'] = comparison['L1_dist'].rank().astype(int)\n",
    "comparison['L2_rank'] = comparison['L2_dist'].rank().astype(int)\n",
    "comparison['Linf_rank'] = comparison['Linf_dist'].rank().astype(int)\n",
    "\n",
    "# Exclude Witch Creature itself (distance 0)\n",
    "comparison = comparison[comparison['creature'] != 'Witch Creature']\n",
    "\n",
    "print(\"Distance to Witch Creature — Different Norms Give Different Rankings!\")\n",
    "print(\"=\"*85)\n",
    "print(comparison.sort_values('L2_dist')[['creature', 'L1_dist', 'L2_dist', 'Linf_dist', \n",
    "                                          'L1_rank', 'L2_rank', 'Linf_rank']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight ranking differences\n",
    "print(\"\\nTop 5 Most Similar to Witch Creature by Each Norm:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nL1 (Manhattan):\")\n",
    "for _, row in comparison.nsmallest(5, 'L1_dist').iterrows():\n",
    "    print(f\"  {row['creature']:25} distance = {row['L1_dist']:.3f}\")\n",
    "\n",
    "print(\"\\nL2 (Euclidean):\")\n",
    "for _, row in comparison.nsmallest(5, 'L2_dist').iterrows():\n",
    "    print(f\"  {row['creature']:25} distance = {row['L2_dist']:.3f}\")\n",
    "\n",
    "print(\"\\nL∞ (Max):\")\n",
    "for _, row in comparison.nsmallest(5, 'Linf_dist').iterrows():\n",
    "    print(f\"  {row['creature']:25} distance = {row['Linf_dist']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### Why Do Rankings Differ?\n",
    "\n",
    "Different norms weight the feature differences differently:\n",
    "\n",
    "- **L2** penalizes large differences more heavily (squared differences)\n",
    "- **L1** treats all differences linearly (no extra penalty for big gaps)\n",
    "- **L∞** only cares about the single largest difference\n",
    "\n",
    "This matters! If one creature differs on a single trait dramatically, L∞ will flag it as distant, while L1 might not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature-level breakdown for selected creatures\n",
    "print(\"Feature-Level Comparison: Witch Creature vs Selected Creatures\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "witch_features = X[witch_idx]\n",
    "print(f\"\\nWitch Creature: {witch_features}\")\n",
    "print(f\"Features: {behavioral_features}\")\n",
    "\n",
    "compare_creatures = ['Maw Beast', 'Stakdur', 'Cave Bat', 'Yeller Frog']\n",
    "\n",
    "for creature_name in compare_creatures:\n",
    "    idx = np.where(names == creature_name)[0][0]\n",
    "    features = X[idx]\n",
    "    diffs = np.abs(witch_features - features)\n",
    "    \n",
    "    print(f\"\\n{creature_name}:\")\n",
    "    print(f\"  Features:    {features}\")\n",
    "    print(f\"  |Diff|:      {diffs.round(2)}\")\n",
    "    print(f\"  L1 = sum(|diff|) = {diffs.sum():.3f}\")\n",
    "    print(f\"  L2 = sqrt(sum(diff²)) = {np.sqrt(np.sum(diffs**2)):.3f}\")\n",
    "    print(f\"  L∞ = max(|diff|) = {diffs.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Part 4: Norm Sensitivity to Outliers\n",
    "\n",
    "A crucial difference: **L2 is more sensitive to large differences** than L1.\n",
    "\n",
    "This has practical implications:\n",
    "- L2 heavily penalizes outliers (one big difference dominates)\n",
    "- L1 treats all differences equally (more robust to outliers)\n",
    "\n",
    "*\"When measuring expedition success, do you penalize one disastrous outcome more than five small failures? The Colonel would say yes—one catastrophe outweighs minor setbacks.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate outlier sensitivity\n",
    "print(\"Outlier Sensitivity: L1 vs L2\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Case 1: Many small differences\n",
    "vec_a = np.array([0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "vec_b = np.array([0.2, 0.2, 0.2, 0.2, 0.2])  # All features differ by 0.2\n",
    "\n",
    "l1_case1 = np.sum(np.abs(vec_b - vec_a))\n",
    "l2_case1 = np.sqrt(np.sum((vec_b - vec_a)**2))\n",
    "\n",
    "print(\"\\nCase 1: Many small differences\")\n",
    "print(f\"  Vector A: {vec_a}\")\n",
    "print(f\"  Vector B: {vec_b}\")\n",
    "print(f\"  L1 distance: {l1_case1:.4f}\")\n",
    "print(f\"  L2 distance: {l2_case1:.4f}\")\n",
    "\n",
    "# Case 2: One large difference (same L1 sum)\n",
    "vec_c = np.array([1.0, 0.0, 0.0, 0.0, 0.0])  # One feature differs by 1.0\n",
    "\n",
    "l1_case2 = np.sum(np.abs(vec_c - vec_a))\n",
    "l2_case2 = np.sqrt(np.sum((vec_c - vec_a)**2))\n",
    "\n",
    "print(\"\\nCase 2: One large difference (same L1 total)\")\n",
    "print(f\"  Vector A: {vec_a}\")\n",
    "print(f\"  Vector C: {vec_c}\")\n",
    "print(f\"  L1 distance: {l1_case2:.4f}\")\n",
    "print(f\"  L2 distance: {l2_case2:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Key insight: L1 distances are equal, but L2 treats them differently!\")\n",
    "print(f\"  L2 ratio (Case2/Case1): {l2_case2/l2_case1:.2f}x\")\n",
    "print(\"  L2 penalizes the concentrated outlier more heavily.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Part 5: Visualizing Distance Contours\n",
    "\n",
    "Let's visualize what \"nearby\" means under different norms by plotting distance contours from a reference creature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2D visualization: aggression vs territoriality\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Reference point: Witch Creature\n",
    "ref_x, ref_y = creature_vectors[creature_vectors['common_name'] == 'Witch Creature'][['aggression', 'territoriality']].values[0]\n",
    "\n",
    "# Create grid\n",
    "xx, yy = np.meshgrid(np.linspace(0, 1, 100), np.linspace(0, 1, 100))\n",
    "\n",
    "# L2 distances\n",
    "l2_grid = np.sqrt((xx - ref_x)**2 + (yy - ref_y)**2)\n",
    "\n",
    "# L1 distances\n",
    "l1_grid = np.abs(xx - ref_x) + np.abs(yy - ref_y)\n",
    "\n",
    "# Plot L2 contours\n",
    "ax = axes[0]\n",
    "contour_l2 = ax.contour(xx, yy, l2_grid, levels=[0.2, 0.4, 0.6, 0.8], colors='green', linewidths=2)\n",
    "ax.clabel(contour_l2, inline=True, fontsize=10, fmt='%.1f')\n",
    "\n",
    "# Plot creatures\n",
    "for _, row in creature_vectors.iterrows():\n",
    "    color = 'red' if row['common_name'] == 'Witch Creature' else 'steelblue'\n",
    "    size = 200 if row['common_name'] == 'Witch Creature' else 80\n",
    "    ax.scatter(row['aggression'], row['territoriality'], c=color, s=size, edgecolor='black', alpha=0.7)\n",
    "    if row['common_name'] in ['Witch Creature', 'Maw Beast', 'Stakdur', 'Cave Bat']:\n",
    "        ax.annotate(row['common_name'], (row['aggression']+0.02, row['territoriality']+0.02), fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Aggression', fontsize=12)\n",
    "ax.set_ylabel('Territoriality', fontsize=12)\n",
    "ax.set_title('L2 (Euclidean) Distance Contours from Witch Creature', fontsize=12)\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(-0.05, 1.05)\n",
    "\n",
    "# Plot L1 contours\n",
    "ax = axes[1]\n",
    "contour_l1 = ax.contour(xx, yy, l1_grid, levels=[0.2, 0.4, 0.6, 0.8], colors='purple', linewidths=2)\n",
    "ax.clabel(contour_l1, inline=True, fontsize=10, fmt='%.1f')\n",
    "\n",
    "# Plot creatures\n",
    "for _, row in creature_vectors.iterrows():\n",
    "    color = 'red' if row['common_name'] == 'Witch Creature' else 'steelblue'\n",
    "    size = 200 if row['common_name'] == 'Witch Creature' else 80\n",
    "    ax.scatter(row['aggression'], row['territoriality'], c=color, s=size, edgecolor='black', alpha=0.7)\n",
    "    if row['common_name'] in ['Witch Creature', 'Maw Beast', 'Stakdur', 'Cave Bat']:\n",
    "        ax.annotate(row['common_name'], (row['aggression']+0.02, row['territoriality']+0.02), fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Aggression', fontsize=12)\n",
    "ax.set_ylabel('Territoriality', fontsize=12)\n",
    "ax.set_title('L1 (Manhattan) Distance Contours from Witch Creature', fontsize=12)\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(-0.05, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice: L2 contours are circles; L1 contours are diamonds.\")\n",
    "print(\"Creatures in different positions relative to contours under each norm!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Part 6: Norms in Machine Learning — Regularization\n",
    "\n",
    "The L1 and L2 norms appear throughout machine learning, especially in **regularization**:\n",
    "\n",
    "| Regularization | Norm | Effect | ML Name |\n",
    "|---------------|------|--------|----------|\n",
    "| L2 | $\\|\\mathbf{w}\\|_2^2 = \\sum w_i^2$ | Shrinks all weights toward zero | **Ridge** |\n",
    "| L1 | $\\|\\mathbf{w}\\|_1 = \\sum |w_i|$ | Drives some weights exactly to zero | **Lasso** |\n",
    "\n",
    "The geometric reason: L1's diamond shape has corners on the axes, making it more likely to \"hit\" at a point where some coordinates are exactly zero.\n",
    "\n",
    "*\"The Archives found that when classifying manuscripts, some features matter immensely while others are noise. L1 regularization automatically identifies which features to ignore—it's like the algorithm learns to focus on what's important.\"*  \n",
    "— Computational stylometry notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate why L1 leads to sparsity\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Draw L1 unit ball (diamond)\n",
    "x_l1 = np.array([1, 0, -1, 0, 1])\n",
    "y_l1 = np.array([0, 1, 0, -1, 0])\n",
    "ax.fill(x_l1, y_l1, alpha=0.3, color='purple', label='L1 constraint region')\n",
    "ax.plot(x_l1, y_l1, 'purple', linewidth=2)\n",
    "\n",
    "# Draw L2 unit ball (circle)\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "ax.fill(np.cos(theta), np.sin(theta), alpha=0.3, color='green', label='L2 constraint region')\n",
    "ax.plot(np.cos(theta), np.sin(theta), 'green', linewidth=2)\n",
    "\n",
    "# Draw some objective function contours (ellipses centered off-origin)\n",
    "center = np.array([0.8, 0.6])\n",
    "for r in [0.3, 0.5, 0.7, 0.9, 1.1]:\n",
    "    ellipse_x = center[0] + r * np.cos(theta)\n",
    "    ellipse_y = center[1] + r * np.sin(theta)\n",
    "    ax.plot(ellipse_x, ellipse_y, 'gray', linewidth=1, alpha=0.5)\n",
    "\n",
    "ax.scatter(*center, s=100, c='red', marker='*', zorder=10, label='Unconstrained optimum')\n",
    "\n",
    "# Mark where constraints meet objective\n",
    "ax.scatter(1, 0, s=150, c='purple', marker='o', zorder=10, edgecolor='black', linewidth=2)\n",
    "ax.annotate('L1 solution\\n(sparse: w₂=0)', (1.05, 0.05), fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.scatter(0.8, 0.6, s=150, c='green', marker='o', zorder=10, edgecolor='black', linewidth=2)\n",
    "ax.annotate('L2 solution\\n(both weights ≠ 0)', (0.65, 0.75), fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_xlim(-1.5, 1.8)\n",
    "ax.set_ylim(-1.5, 1.5)\n",
    "ax.set_xlabel('Weight w₁', fontsize=12)\n",
    "ax.set_ylabel('Weight w₂', fontsize=12)\n",
    "ax.set_title('Why L1 Regularization Creates Sparse Solutions\\n(Constraint touches objective at corner → w₂=0)', fontsize=13)\n",
    "ax.legend(loc='lower left', fontsize=10)\n",
    "ax.set_aspect('equal')\n",
    "ax.axhline(0, color='black', linewidth=0.5)\n",
    "ax.axvline(0, color='black', linewidth=0.5)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Part 7: When to Use Which Norm\n",
    "\n",
    "| Situation | Recommended Norm | Reason |\n",
    "|-----------|-----------------|--------|\n",
    "| Standard distance/similarity | L2 | Intuitive \"straight line\" interpretation |\n",
    "| Robust to outliers | L1 | Less sensitive to extreme values |\n",
    "| Feature selection needed | L1 (Lasso) | Drives irrelevant weights to zero |\n",
    "| All features likely important | L2 (Ridge) | Shrinks all weights, keeps all |\n",
    "| High-dimensional data | L1 or L2 | L1 for sparsity, L2 for stability |\n",
    "| Grid/graph distances | L1 | Natural for networks, city blocks |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical example: Which norm for creature classification?\n",
    "print(\"Practical Decision: Classifying Dangerous vs Safe Creatures\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "# Define dangerous creatures\n",
    "dangerous = ['Witch Creature', 'Stakdur', 'Maw Beast', 'Wharver', 'Marsh Hornet']\n",
    "creature_vectors['is_dangerous'] = creature_vectors['common_name'].isin(dangerous)\n",
    "\n",
    "# Test creature: Stone Spine Lizard\n",
    "test_creature = 'Stone Spine Lizard'\n",
    "test_idx = creature_vectors[creature_vectors['common_name'] == test_creature].index[0]\n",
    "test_vector = X[test_idx].reshape(1, -1)\n",
    "\n",
    "# Find k=3 nearest neighbors under each norm\n",
    "l1_dists = cdist(test_vector, X, metric='cityblock')[0]\n",
    "l2_dists = cdist(test_vector, X, metric='euclidean')[0]\n",
    "\n",
    "# Exclude self\n",
    "l1_dists[test_idx] = np.inf\n",
    "l2_dists[test_idx] = np.inf\n",
    "\n",
    "k = 3\n",
    "l1_neighbors = np.argsort(l1_dists)[:k]\n",
    "l2_neighbors = np.argsort(l2_dists)[:k]\n",
    "\n",
    "print(f\"\\nClassifying: {test_creature}\")\n",
    "print(f\"Actual status: {'Dangerous' if creature_vectors.loc[test_idx, 'is_dangerous'] else 'Safe'}\")\n",
    "\n",
    "print(f\"\\n3-NN using L1 (Manhattan):\")\n",
    "l1_dangerous_count = 0\n",
    "for idx in l1_neighbors:\n",
    "    name = names[idx]\n",
    "    status = 'DANGEROUS' if creature_vectors.loc[idx, 'is_dangerous'] else 'safe'\n",
    "    if status == 'DANGEROUS':\n",
    "        l1_dangerous_count += 1\n",
    "    print(f\"  {name:25} - {status}\")\n",
    "print(f\"  Prediction: {'DANGEROUS' if l1_dangerous_count >= 2 else 'safe'} (majority vote)\")\n",
    "\n",
    "print(f\"\\n3-NN using L2 (Euclidean):\")\n",
    "l2_dangerous_count = 0\n",
    "for idx in l2_neighbors:\n",
    "    name = names[idx]\n",
    "    status = 'DANGEROUS' if creature_vectors.loc[idx, 'is_dangerous'] else 'safe'\n",
    "    if status == 'DANGEROUS':\n",
    "        l2_dangerous_count += 1\n",
    "    print(f\"  {name:25} - {status}\")\n",
    "print(f\"  Prediction: {'DANGEROUS' if l2_dangerous_count >= 2 else 'safe'} (majority vote)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Concept | Key Insight | Densworld Example |\n",
    "|---------|-------------|-------------------|\n",
    "| **L2 (Euclidean)** | Straight-line distance; penalizes large differences | Vagabu Olt measuring \"as the crow flies\" |\n",
    "| **L1 (Manhattan)** | Grid distance; robust to outliers | The Pickbox Man navigating tunnels |\n",
    "| **Unit Circles** | L2 = circle, L1 = diamond | Shape of \"nearby\" changes with norm |\n",
    "| **Ranking Changes** | Different norms → different nearest neighbors | Witch Creature's neighbors depend on norm |\n",
    "| **Outlier Sensitivity** | L2 more sensitive; L1 more robust | One extreme trait vs. many mild ones |\n",
    "| **Regularization** | L1 → sparsity (Lasso); L2 → shrinkage (Ridge) | Feature selection for manuscript analysis |\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Rank Comparison\n",
    "\n",
    "Choose a creature (not Witch Creature) and find its 5 nearest neighbors under both L1 and L2 norms. Do the rankings differ? Which creatures change rank the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "# Hint: Follow the pattern from Part 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### Exercise 2: Create a Scenario\n",
    "\n",
    "Create two synthetic 5-dimensional vectors where:\n",
    "- L1 distance is 2.0\n",
    "- L2 distance is very different (either much larger or much smaller than L1)\n",
    "\n",
    "Explain why this happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "# Hint: Think about concentrated vs. spread-out differences\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "### Exercise 3: Boundary Observations\n",
    "\n",
    "Using the `dens_boundary` dataset, calculate the L1 and L2 norms of the measurement error vectors (treat each observation as a point in feature space using `stability_index` and `measurement_error`). Which observations have the largest norms? Are they the same under both norms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n",
    "# Hint: np.abs() for L1, np.sqrt() for L2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "### Exercise 4: K-NN Classification\n",
    "\n",
    "Implement a simple k-NN classifier that can switch between L1 and L2 distance. Test it on classifying creatures as \"high_aggression\" (aggression > 0.5) using all behavioral features. Does the choice of norm affect accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Your code here\n",
    "# Hint: Use leave-one-out cross-validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Lesson\n",
    "\n",
    "In **Lesson 3: The Dot Product and Similarity**, we'll explore a different way to measure how \"alike\" two vectors are—not by their distance, but by their **alignment**. The dot product reveals whether creatures (or manuscripts) \"point in the same direction\" in feature space.\n",
    "\n",
    "*\"Distance tells you how far apart things are. The dot product tells you whether they're pointed the same way. A Marsh Hornet and a Stakdur may be distant in space, but they share the same predatory intent.\"*  \n",
    "— Boffa Trent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
